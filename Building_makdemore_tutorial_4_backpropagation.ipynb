{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08571571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb6acfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189a1d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "384ea1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "    X, Y = [], []\n",
    "  \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778b9d4",
   "metadata": {},
   "source": [
    "## above is biolerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84311a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function \n",
    "# to compare with manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "790b58d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "# the dimensionality of the character embedding vectors\n",
    "n_embd = 10 \n",
    "# the number of neurons in the hidden layer of the MLP\n",
    "n_hidden = 64 \n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) \n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "# b1 is useless here because of BN\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 \n",
    "\n",
    "\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# initializating many of these parameters in non-standard ways to avoid trouble later (e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass).\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "\n",
    "\n",
    "# number of parameters in total\n",
    "print(sum(p.nelement() for p in parameters)) \n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3a525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a39ae019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3540, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "# embedding\n",
    "emb = C[Xb] \n",
    "# concatenate the vectors\n",
    "embcat = emb.view(emb.shape[0], -1) \n",
    "\n",
    "# Linear layer 1\n",
    "# hidden layer pre-activation\n",
    "hprebn = embcat @ W1 + b1 \n",
    "\n",
    "\n",
    "\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "\n",
    "# Non-linearity\n",
    "# still part of the hidden layer\n",
    "h = torch.tanh(hpreact) \n",
    "\n",
    "\n",
    "# Linear layer 2\n",
    "# output layer\n",
    "logits = h @ W2 + b2 \n",
    "\n",
    "# spelling out the cross entropy loss\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "# subtract max for numerical stability\n",
    "norm_logits = logits - logit_maxes \n",
    "\n",
    "\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a29a9",
   "metadata": {},
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8822db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlogprobs.shape\n",
    "# dlogprobs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2458ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
       "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b5e887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlogprobs[range(n), Yb].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c31195a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3751407d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "539feef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "# dcounts = counts_sum_inv * dprobs\n",
    "# dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "# dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "# dnorm_logits = counts * dcounts\n",
    "# dlogits = dnorm_logits.clone()\n",
    "# dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "# dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aed418bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dh, dh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c40fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "\n",
    "\n",
    "dh = dlogits @ W2.T  #make the shapes work out\n",
    "\n",
    "# da * dd\n",
    "# dlogits and multiply\n",
    "\n",
    "# dlogits\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "\n",
    "\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "# dC = torch.zeros_like(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7569452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee212f27",
   "metadata": {},
   "source": [
    "## a11, a12\n",
    "## a21, a22\n",
    "#### ---> b1  b2, where:\n",
    "#### b1 = 1/(n-1)*(a11 + a21)\n",
    "#### b2 = 1/(n-1)((a12 + a22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4d8de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204d2fba",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3f3faec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 10]), torch.Size([27, 10]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass: emb = C[Xb]\n",
    "\n",
    "emb.shape, C.shape, Xb.shape\n",
    "\n",
    "# There are integers in side C, which integer we wan to to use and package them into the sensor. \n",
    "\n",
    "# Now, we have to route the gradient, which row of C does the embeddings come from. So that we can undo the\n",
    "# indexing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a9659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03da2d60",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60a5c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63f04326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.353985071182251 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c1b1037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 5.820766091346741e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f1d9eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34112be0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0667, 0.0814, 0.0186, 0.0526, 0.0199, 0.0854, 0.0238, 0.0356, 0.0178,\n",
       "         0.0312, 0.0345, 0.0330, 0.0374, 0.0278, 0.0367, 0.0135, 0.0095, 0.0205,\n",
       "         0.0160, 0.0574, 0.0499, 0.0224, 0.0243, 0.0724, 0.0616, 0.0267, 0.0234],\n",
       "        [0.0518, 0.0554, 0.0914, 0.0572, 0.0358, 0.0360, 0.0175, 0.0414, 0.0203,\n",
       "         0.0243, 0.0517, 0.0410, 0.0461, 0.0258, 0.0445, 0.0371, 0.0290, 0.0180,\n",
       "         0.0230, 0.0388, 0.0202, 0.0227, 0.0141, 0.0680, 0.0257, 0.0362, 0.0270]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9dc41f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0667,  0.0814,  0.0186,  0.0526,  0.0199,  0.0854,  0.0238,  0.0356,\n",
       "        -0.9822,  0.0312,  0.0345,  0.0330,  0.0374,  0.0278,  0.0367,  0.0135,\n",
       "         0.0095,  0.0205,  0.0160,  0.0574,  0.0499,  0.0224,  0.0243,  0.0724,\n",
       "         0.0616,  0.0267,  0.0234], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6967ae4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1642e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "292b6b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14384c950>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d477cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2e76bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa776952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e2e21bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " tensor([[-3.3036e-04, -7.7362e-04,  1.2221e-03,  ..., -2.2994e-04,\n",
       "          -8.6389e-04, -9.1991e-04],\n",
       "         [-3.0579e-05,  1.3432e-03,  5.1699e-04,  ...,  5.5792e-04,\n",
       "          -1.7807e-03, -2.4296e-03],\n",
       "         [ 2.2629e-04,  2.1589e-03,  6.8046e-04,  ...,  2.6955e-03,\n",
       "          -1.5441e-04,  6.4322e-04],\n",
       "         ...,\n",
       "         [-9.5283e-04,  1.4971e-03, -1.3172e-03,  ..., -2.2479e-03,\n",
       "          -1.5713e-03, -1.4500e-03],\n",
       "         [-4.6439e-04,  3.2566e-04, -1.3036e-03,  ...,  1.9837e-04,\n",
       "           3.1971e-04,  8.7024e-04],\n",
       "         [-7.6897e-05,  3.2394e-03,  2.6904e-03,  ..., -7.7238e-04,\n",
       "           5.4821e-04,  7.5359e-04]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, dhprebn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ade0383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d66e5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "140ab17e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.7846\n",
      "    100/ 200000: 2.3285\n",
      "    200/ 200000: 2.8552\n",
      "    300/ 200000: 2.5941\n",
      "    400/ 200000: 2.5171\n",
      "    500/ 200000: 2.7967\n",
      "    600/ 200000: 2.4346\n",
      "    700/ 200000: 2.3966\n",
      "    800/ 200000: 2.3931\n",
      "    900/ 200000: 2.1684\n",
      "   1000/ 200000: 2.2452\n",
      "   1100/ 200000: 2.2398\n",
      "   1200/ 200000: 2.7076\n",
      "   1300/ 200000: 2.7515\n",
      "   1400/ 200000: 2.3485\n",
      "   1500/ 200000: 2.4486\n",
      "   1600/ 200000: 2.5803\n",
      "   1700/ 200000: 2.3613\n",
      "   1800/ 200000: 2.3415\n",
      "   1900/ 200000: 2.3779\n",
      "   2000/ 200000: 2.3014\n",
      "   2100/ 200000: 2.4289\n",
      "   2200/ 200000: 1.9612\n",
      "   2300/ 200000: 2.4265\n",
      "   2400/ 200000: 2.8966\n",
      "   2500/ 200000: 2.3695\n",
      "   2600/ 200000: 2.3160\n",
      "   2700/ 200000: 2.1737\n",
      "   2800/ 200000: 2.1881\n",
      "   2900/ 200000: 2.2890\n",
      "   3000/ 200000: 2.2213\n",
      "   3100/ 200000: 2.6342\n",
      "   3200/ 200000: 2.1341\n",
      "   3300/ 200000: 2.2326\n",
      "   3400/ 200000: 2.2510\n",
      "   3500/ 200000: 2.4006\n",
      "   3600/ 200000: 2.1220\n",
      "   3700/ 200000: 2.2014\n",
      "   3800/ 200000: 2.4010\n",
      "   3900/ 200000: 2.3624\n",
      "   4000/ 200000: 2.1944\n",
      "   4100/ 200000: 2.4579\n",
      "   4200/ 200000: 2.4650\n",
      "   4300/ 200000: 2.6046\n",
      "   4400/ 200000: 2.1439\n",
      "   4500/ 200000: 2.1194\n",
      "   4600/ 200000: 2.1477\n",
      "   4700/ 200000: 2.1934\n",
      "   4800/ 200000: 2.2106\n",
      "   4900/ 200000: 2.4811\n",
      "   5000/ 200000: 2.3208\n",
      "   5100/ 200000: 2.3536\n",
      "   5200/ 200000: 2.1494\n",
      "   5300/ 200000: 1.9349\n",
      "   5400/ 200000: 2.7548\n",
      "   5500/ 200000: 2.4600\n",
      "   5600/ 200000: 2.5024\n",
      "   5700/ 200000: 2.3812\n",
      "   5800/ 200000: 2.3460\n",
      "   5900/ 200000: 1.9150\n",
      "   6000/ 200000: 2.1319\n",
      "   6100/ 200000: 2.4458\n",
      "   6200/ 200000: 2.5463\n",
      "   6300/ 200000: 2.3415\n",
      "   6400/ 200000: 2.5286\n",
      "   6500/ 200000: 2.1331\n",
      "   6600/ 200000: 2.4268\n",
      "   6700/ 200000: 2.3862\n",
      "   6800/ 200000: 2.1035\n",
      "   6900/ 200000: 2.3997\n",
      "   7000/ 200000: 2.4709\n",
      "   7100/ 200000: 2.3402\n",
      "   7200/ 200000: 2.2773\n",
      "   7300/ 200000: 2.2856\n",
      "   7400/ 200000: 2.1367\n",
      "   7500/ 200000: 2.4163\n",
      "   7600/ 200000: 2.6517\n",
      "   7700/ 200000: 1.9639\n",
      "   7800/ 200000: 2.0749\n",
      "   7900/ 200000: 2.5137\n",
      "   8000/ 200000: 2.0535\n",
      "   8100/ 200000: 2.2598\n",
      "   8200/ 200000: 2.6269\n",
      "   8300/ 200000: 2.2467\n",
      "   8400/ 200000: 2.3978\n",
      "   8500/ 200000: 2.4743\n",
      "   8600/ 200000: 2.2888\n",
      "   8700/ 200000: 2.0362\n",
      "   8800/ 200000: 2.2008\n",
      "   8900/ 200000: 2.3732\n",
      "   9000/ 200000: 2.1712\n",
      "   9100/ 200000: 2.0595\n",
      "   9200/ 200000: 1.9408\n",
      "   9300/ 200000: 2.2742\n",
      "   9400/ 200000: 2.5671\n",
      "   9500/ 200000: 2.6083\n",
      "   9600/ 200000: 2.3102\n",
      "   9700/ 200000: 2.7074\n",
      "   9800/ 200000: 2.2509\n",
      "   9900/ 200000: 2.0833\n",
      "  10000/ 200000: 2.1940\n",
      "  10100/ 200000: 2.4744\n",
      "  10200/ 200000: 2.5201\n",
      "  10300/ 200000: 1.9771\n",
      "  10400/ 200000: 2.8187\n",
      "  10500/ 200000: 2.3033\n",
      "  10600/ 200000: 2.3352\n",
      "  10700/ 200000: 2.2467\n",
      "  10800/ 200000: 2.2526\n",
      "  10900/ 200000: 2.3863\n",
      "  11000/ 200000: 1.8761\n",
      "  11100/ 200000: 2.0107\n",
      "  11200/ 200000: 2.0833\n",
      "  11300/ 200000: 2.3080\n",
      "  11400/ 200000: 2.3139\n",
      "  11500/ 200000: 2.2033\n",
      "  11600/ 200000: 2.1484\n",
      "  11700/ 200000: 2.1262\n",
      "  11800/ 200000: 2.2887\n",
      "  11900/ 200000: 2.6229\n",
      "  12000/ 200000: 2.2674\n",
      "  12100/ 200000: 1.9299\n",
      "  12200/ 200000: 2.5174\n",
      "  12300/ 200000: 2.2811\n",
      "  12400/ 200000: 2.2182\n",
      "  12500/ 200000: 2.1267\n",
      "  12600/ 200000: 2.5251\n",
      "  12700/ 200000: 2.1008\n",
      "  12800/ 200000: 2.2200\n",
      "  12900/ 200000: 2.1954\n",
      "  13000/ 200000: 2.2547\n",
      "  13100/ 200000: 2.3860\n",
      "  13200/ 200000: 2.4890\n",
      "  13300/ 200000: 2.1565\n",
      "  13400/ 200000: 2.4161\n",
      "  13500/ 200000: 2.4359\n",
      "  13600/ 200000: 2.2845\n",
      "  13700/ 200000: 2.3172\n",
      "  13800/ 200000: 2.3201\n",
      "  13900/ 200000: 1.9149\n",
      "  14000/ 200000: 2.6921\n",
      "  14100/ 200000: 2.5117\n",
      "  14200/ 200000: 2.0691\n",
      "  14300/ 200000: 2.4056\n",
      "  14400/ 200000: 2.2059\n",
      "  14500/ 200000: 2.7060\n",
      "  14600/ 200000: 2.3217\n",
      "  14700/ 200000: 2.2507\n",
      "  14800/ 200000: 2.4361\n",
      "  14900/ 200000: 2.2044\n",
      "  15000/ 200000: 2.0640\n",
      "  15100/ 200000: 2.2874\n",
      "  15200/ 200000: 2.7453\n",
      "  15300/ 200000: 2.4083\n",
      "  15400/ 200000: 2.0832\n",
      "  15500/ 200000: 1.9448\n",
      "  15600/ 200000: 2.3423\n",
      "  15700/ 200000: 2.3580\n",
      "  15800/ 200000: 2.5131\n",
      "  15900/ 200000: 2.3854\n",
      "  16000/ 200000: 2.4491\n",
      "  16100/ 200000: 2.2296\n",
      "  16200/ 200000: 2.1326\n",
      "  16300/ 200000: 2.7166\n",
      "  16400/ 200000: 2.2176\n",
      "  16500/ 200000: 2.2404\n",
      "  16600/ 200000: 2.1527\n",
      "  16700/ 200000: 2.1352\n",
      "  16800/ 200000: 2.3640\n",
      "  16900/ 200000: 2.1807\n",
      "  17000/ 200000: 2.2807\n",
      "  17100/ 200000: 2.2770\n",
      "  17200/ 200000: 2.3292\n",
      "  17300/ 200000: 2.4354\n",
      "  17400/ 200000: 2.4788\n",
      "  17500/ 200000: 2.1048\n",
      "  17600/ 200000: 1.9997\n",
      "  17700/ 200000: 2.2448\n",
      "  17800/ 200000: 2.3070\n",
      "  17900/ 200000: 2.4599\n",
      "  18000/ 200000: 2.0130\n",
      "  18100/ 200000: 2.3852\n",
      "  18200/ 200000: 2.3990\n",
      "  18300/ 200000: 2.0778\n",
      "  18400/ 200000: 2.4392\n",
      "  18500/ 200000: 1.8543\n",
      "  18600/ 200000: 2.3642\n",
      "  18700/ 200000: 2.3345\n",
      "  18800/ 200000: 2.4062\n",
      "  18900/ 200000: 2.1490\n",
      "  19000/ 200000: 2.4547\n",
      "  19100/ 200000: 2.3078\n",
      "  19200/ 200000: 1.9993\n",
      "  19300/ 200000: 2.2963\n",
      "  19400/ 200000: 2.2875\n",
      "  19500/ 200000: 1.8960\n",
      "  19600/ 200000: 2.5192\n",
      "  19700/ 200000: 2.3121\n",
      "  19800/ 200000: 2.4437\n",
      "  19900/ 200000: 1.9464\n",
      "  20000/ 200000: 2.3592\n",
      "  20100/ 200000: 1.9892\n",
      "  20200/ 200000: 2.3134\n",
      "  20300/ 200000: 2.2274\n",
      "  20400/ 200000: 2.1925\n",
      "  20500/ 200000: 2.3862\n",
      "  20600/ 200000: 1.9587\n",
      "  20700/ 200000: 1.9517\n",
      "  20800/ 200000: 2.2551\n",
      "  20900/ 200000: 2.1711\n",
      "  21000/ 200000: 2.5202\n",
      "  21100/ 200000: 2.2343\n",
      "  21200/ 200000: 2.4759\n",
      "  21300/ 200000: 2.7391\n",
      "  21400/ 200000: 1.8080\n",
      "  21500/ 200000: 2.1549\n",
      "  21600/ 200000: 2.1639\n",
      "  21700/ 200000: 2.1197\n",
      "  21800/ 200000: 2.2459\n",
      "  21900/ 200000: 2.9226\n",
      "  22000/ 200000: 1.8680\n",
      "  22100/ 200000: 2.2033\n",
      "  22200/ 200000: 2.2879\n",
      "  22300/ 200000: 2.0245\n",
      "  22400/ 200000: 2.7217\n",
      "  22500/ 200000: 2.5049\n",
      "  22600/ 200000: 2.2640\n",
      "  22700/ 200000: 2.1347\n",
      "  22800/ 200000: 2.0740\n",
      "  22900/ 200000: 2.1984\n",
      "  23000/ 200000: 1.9868\n",
      "  23100/ 200000: 2.4717\n",
      "  23200/ 200000: 1.8945\n",
      "  23300/ 200000: 2.2761\n",
      "  23400/ 200000: 2.1674\n",
      "  23500/ 200000: 2.1531\n",
      "  23600/ 200000: 2.1135\n",
      "  23700/ 200000: 2.2031\n",
      "  23800/ 200000: 2.3674\n",
      "  23900/ 200000: 2.4204\n",
      "  24000/ 200000: 2.5673\n",
      "  24100/ 200000: 1.9483\n",
      "  24200/ 200000: 2.0280\n",
      "  24300/ 200000: 1.9042\n",
      "  24400/ 200000: 2.2890\n",
      "  24500/ 200000: 2.1951\n",
      "  24600/ 200000: 2.3508\n",
      "  24700/ 200000: 1.7844\n",
      "  24800/ 200000: 1.9031\n",
      "  24900/ 200000: 1.8058\n",
      "  25000/ 200000: 2.2651\n",
      "  25100/ 200000: 1.9320\n",
      "  25200/ 200000: 2.3285\n",
      "  25300/ 200000: 2.3131\n",
      "  25400/ 200000: 1.8872\n",
      "  25500/ 200000: 1.9795\n",
      "  25600/ 200000: 2.3065\n",
      "  25700/ 200000: 2.4186\n",
      "  25800/ 200000: 2.2957\n",
      "  25900/ 200000: 2.1889\n",
      "  26000/ 200000: 2.3635\n",
      "  26100/ 200000: 2.1563\n",
      "  26200/ 200000: 2.4027\n",
      "  26300/ 200000: 1.9604\n",
      "  26400/ 200000: 2.1032\n",
      "  26500/ 200000: 2.1736\n",
      "  26600/ 200000: 2.2153\n",
      "  26700/ 200000: 1.9144\n",
      "  26800/ 200000: 2.4582\n",
      "  26900/ 200000: 2.2520\n",
      "  27000/ 200000: 2.3684\n",
      "  27100/ 200000: 2.4578\n",
      "  27200/ 200000: 2.3320\n",
      "  27300/ 200000: 2.0839\n",
      "  27400/ 200000: 2.0274\n",
      "  27500/ 200000: 2.4346\n",
      "  27600/ 200000: 2.3655\n",
      "  27700/ 200000: 2.2064\n",
      "  27800/ 200000: 2.0651\n",
      "  27900/ 200000: 2.5192\n",
      "  28000/ 200000: 2.0674\n",
      "  28100/ 200000: 2.3125\n",
      "  28200/ 200000: 2.2908\n",
      "  28300/ 200000: 1.9088\n",
      "  28400/ 200000: 2.1115\n",
      "  28500/ 200000: 2.0602\n",
      "  28600/ 200000: 2.0936\n",
      "  28700/ 200000: 2.1668\n",
      "  28800/ 200000: 2.1350\n",
      "  28900/ 200000: 2.2510\n",
      "  29000/ 200000: 2.6776\n",
      "  29100/ 200000: 2.0575\n",
      "  29200/ 200000: 2.0679\n",
      "  29300/ 200000: 2.1162\n",
      "  29400/ 200000: 2.2875\n",
      "  29500/ 200000: 2.1444\n",
      "  29600/ 200000: 2.5759\n",
      "  29700/ 200000: 2.2419\n",
      "  29800/ 200000: 2.2299\n",
      "  29900/ 200000: 2.2762\n",
      "  30000/ 200000: 2.4580\n",
      "  30100/ 200000: 2.1260\n",
      "  30200/ 200000: 2.3434\n",
      "  30300/ 200000: 2.1424\n",
      "  30400/ 200000: 2.4629\n",
      "  30500/ 200000: 2.1722\n",
      "  30600/ 200000: 1.9826\n",
      "  30700/ 200000: 2.3130\n",
      "  30800/ 200000: 2.1133\n",
      "  30900/ 200000: 2.1027\n",
      "  31000/ 200000: 2.2127\n",
      "  31100/ 200000: 1.9931\n",
      "  31200/ 200000: 2.2727\n",
      "  31300/ 200000: 2.4483\n",
      "  31400/ 200000: 2.5773\n",
      "  31500/ 200000: 2.7442\n",
      "  31600/ 200000: 2.3650\n",
      "  31700/ 200000: 2.3878\n",
      "  31800/ 200000: 2.2181\n",
      "  31900/ 200000: 2.1901\n",
      "  32000/ 200000: 2.3777\n",
      "  32100/ 200000: 1.8710\n",
      "  32200/ 200000: 2.0888\n",
      "  32300/ 200000: 2.4650\n",
      "  32400/ 200000: 2.1930\n",
      "  32500/ 200000: 2.2896\n",
      "  32600/ 200000: 2.3005\n",
      "  32700/ 200000: 1.9816\n",
      "  32800/ 200000: 2.1715\n",
      "  32900/ 200000: 2.1991\n",
      "  33000/ 200000: 2.2653\n",
      "  33100/ 200000: 2.2778\n",
      "  33200/ 200000: 2.0965\n",
      "  33300/ 200000: 2.2784\n",
      "  33400/ 200000: 2.1663\n",
      "  33500/ 200000: 2.2953\n",
      "  33600/ 200000: 2.1008\n",
      "  33700/ 200000: 1.7768\n",
      "  33800/ 200000: 1.9113\n",
      "  33900/ 200000: 2.0174\n",
      "  34000/ 200000: 2.0433\n",
      "  34100/ 200000: 2.2492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  34200/ 200000: 2.1048\n",
      "  34300/ 200000: 2.1510\n",
      "  34400/ 200000: 2.4536\n",
      "  34500/ 200000: 2.3423\n",
      "  34600/ 200000: 2.4822\n",
      "  34700/ 200000: 2.3057\n",
      "  34800/ 200000: 2.0923\n",
      "  34900/ 200000: 1.9027\n",
      "  35000/ 200000: 2.3849\n",
      "  35100/ 200000: 2.3362\n",
      "  35200/ 200000: 2.5206\n",
      "  35300/ 200000: 2.0135\n",
      "  35400/ 200000: 2.6434\n",
      "  35500/ 200000: 2.2733\n",
      "  35600/ 200000: 2.0217\n",
      "  35700/ 200000: 2.2535\n",
      "  35800/ 200000: 2.1019\n",
      "  35900/ 200000: 2.0256\n",
      "  36000/ 200000: 2.1931\n",
      "  36100/ 200000: 2.3359\n",
      "  36200/ 200000: 2.1178\n",
      "  36300/ 200000: 2.2772\n",
      "  36400/ 200000: 2.1026\n",
      "  36500/ 200000: 2.0325\n",
      "  36600/ 200000: 2.2180\n",
      "  36700/ 200000: 2.3011\n",
      "  36800/ 200000: 2.0814\n",
      "  36900/ 200000: 2.6424\n",
      "  37000/ 200000: 2.0245\n",
      "  37100/ 200000: 2.1142\n",
      "  37200/ 200000: 2.4680\n",
      "  37300/ 200000: 2.2867\n",
      "  37400/ 200000: 2.2946\n",
      "  37500/ 200000: 1.6378\n",
      "  37600/ 200000: 2.3705\n",
      "  37700/ 200000: 2.2492\n",
      "  37800/ 200000: 1.9757\n",
      "  37900/ 200000: 2.0964\n",
      "  38000/ 200000: 2.6470\n",
      "  38100/ 200000: 1.9777\n",
      "  38200/ 200000: 2.0949\n",
      "  38300/ 200000: 2.2194\n",
      "  38400/ 200000: 2.1952\n",
      "  38500/ 200000: 1.9746\n",
      "  38600/ 200000: 2.6215\n",
      "  38700/ 200000: 2.8362\n",
      "  38800/ 200000: 2.1853\n",
      "  38900/ 200000: 1.9821\n",
      "  39000/ 200000: 2.1275\n",
      "  39100/ 200000: 1.9639\n",
      "  39200/ 200000: 2.1457\n",
      "  39300/ 200000: 2.2919\n",
      "  39400/ 200000: 2.0447\n",
      "  39500/ 200000: 2.1382\n",
      "  39600/ 200000: 2.1124\n",
      "  39700/ 200000: 2.0843\n",
      "  39800/ 200000: 2.1229\n",
      "  39900/ 200000: 2.1327\n",
      "  40000/ 200000: 2.0093\n",
      "  40100/ 200000: 2.3438\n",
      "  40200/ 200000: 2.1425\n",
      "  40300/ 200000: 2.0818\n",
      "  40400/ 200000: 2.6451\n",
      "  40500/ 200000: 2.1262\n",
      "  40600/ 200000: 1.8644\n",
      "  40700/ 200000: 2.2960\n",
      "  40800/ 200000: 2.7088\n",
      "  40900/ 200000: 2.3681\n",
      "  41000/ 200000: 2.2580\n",
      "  41100/ 200000: 2.3387\n",
      "  41200/ 200000: 1.8459\n",
      "  41300/ 200000: 1.8885\n",
      "  41400/ 200000: 2.1001\n",
      "  41500/ 200000: 2.0569\n",
      "  41600/ 200000: 2.0428\n",
      "  41700/ 200000: 2.3021\n",
      "  41800/ 200000: 2.1098\n",
      "  41900/ 200000: 2.3143\n",
      "  42000/ 200000: 2.2411\n",
      "  42100/ 200000: 1.8808\n",
      "  42200/ 200000: 2.5832\n",
      "  42300/ 200000: 2.4837\n",
      "  42400/ 200000: 1.8075\n",
      "  42500/ 200000: 2.3823\n",
      "  42600/ 200000: 2.1924\n",
      "  42700/ 200000: 2.1855\n",
      "  42800/ 200000: 1.9964\n",
      "  42900/ 200000: 2.3164\n",
      "  43000/ 200000: 2.4429\n",
      "  43100/ 200000: 1.6050\n",
      "  43200/ 200000: 2.2901\n",
      "  43300/ 200000: 2.0645\n",
      "  43400/ 200000: 2.1215\n",
      "  43500/ 200000: 2.1800\n",
      "  43600/ 200000: 2.0041\n",
      "  43700/ 200000: 2.1118\n",
      "  43800/ 200000: 2.0854\n",
      "  43900/ 200000: 2.0636\n",
      "  44000/ 200000: 1.9544\n",
      "  44100/ 200000: 2.0742\n",
      "  44200/ 200000: 2.5926\n",
      "  44300/ 200000: 2.0100\n",
      "  44400/ 200000: 2.4458\n",
      "  44500/ 200000: 2.0291\n",
      "  44600/ 200000: 2.2121\n",
      "  44700/ 200000: 2.1681\n",
      "  44800/ 200000: 2.0071\n",
      "  44900/ 200000: 2.3442\n",
      "  45000/ 200000: 1.8267\n",
      "  45100/ 200000: 2.4019\n",
      "  45200/ 200000: 1.9521\n",
      "  45300/ 200000: 2.1449\n",
      "  45400/ 200000: 2.0771\n",
      "  45500/ 200000: 2.3171\n",
      "  45600/ 200000: 2.2734\n",
      "  45700/ 200000: 2.1983\n",
      "  45800/ 200000: 2.4902\n",
      "  45900/ 200000: 1.9832\n",
      "  46000/ 200000: 2.2424\n",
      "  46100/ 200000: 1.9294\n",
      "  46200/ 200000: 1.7684\n",
      "  46300/ 200000: 1.7346\n",
      "  46400/ 200000: 2.1788\n",
      "  46500/ 200000: 2.2734\n",
      "  46600/ 200000: 2.0710\n",
      "  46700/ 200000: 2.4192\n",
      "  46800/ 200000: 2.3291\n",
      "  46900/ 200000: 2.5565\n",
      "  47000/ 200000: 2.1307\n",
      "  47100/ 200000: 2.0804\n",
      "  47200/ 200000: 2.4310\n",
      "  47300/ 200000: 1.9384\n",
      "  47400/ 200000: 1.9518\n",
      "  47500/ 200000: 2.1036\n",
      "  47600/ 200000: 2.2169\n",
      "  47700/ 200000: 2.1595\n",
      "  47800/ 200000: 2.2597\n",
      "  47900/ 200000: 2.0581\n",
      "  48000/ 200000: 2.6671\n",
      "  48100/ 200000: 2.1417\n",
      "  48200/ 200000: 2.1004\n",
      "  48300/ 200000: 2.0922\n",
      "  48400/ 200000: 2.1023\n",
      "  48500/ 200000: 2.0117\n",
      "  48600/ 200000: 1.9144\n",
      "  48700/ 200000: 1.7277\n",
      "  48800/ 200000: 2.7736\n",
      "  48900/ 200000: 1.8838\n",
      "  49000/ 200000: 1.9668\n",
      "  49100/ 200000: 2.1450\n",
      "  49200/ 200000: 1.8595\n",
      "  49300/ 200000: 2.1592\n",
      "  49400/ 200000: 2.1513\n",
      "  49500/ 200000: 2.5570\n",
      "  49600/ 200000: 2.3416\n",
      "  49700/ 200000: 2.3355\n",
      "  49800/ 200000: 2.3699\n",
      "  49900/ 200000: 2.2211\n",
      "  50000/ 200000: 2.4233\n",
      "  50100/ 200000: 2.2467\n",
      "  50200/ 200000: 1.7545\n",
      "  50300/ 200000: 2.4289\n",
      "  50400/ 200000: 2.3027\n",
      "  50500/ 200000: 2.3206\n",
      "  50600/ 200000: 1.8713\n",
      "  50700/ 200000: 2.4834\n",
      "  50800/ 200000: 2.2364\n",
      "  50900/ 200000: 2.5240\n",
      "  51000/ 200000: 2.7841\n",
      "  51100/ 200000: 2.4239\n",
      "  51200/ 200000: 2.4919\n",
      "  51300/ 200000: 2.5033\n",
      "  51400/ 200000: 2.2767\n",
      "  51500/ 200000: 2.2280\n",
      "  51600/ 200000: 1.9316\n",
      "  51700/ 200000: 2.0449\n",
      "  51800/ 200000: 2.0729\n",
      "  51900/ 200000: 2.1031\n",
      "  52000/ 200000: 2.3241\n",
      "  52100/ 200000: 2.0264\n",
      "  52200/ 200000: 2.2020\n",
      "  52300/ 200000: 2.2642\n",
      "  52400/ 200000: 2.3226\n",
      "  52500/ 200000: 2.2188\n",
      "  52600/ 200000: 1.9060\n",
      "  52700/ 200000: 1.8435\n",
      "  52800/ 200000: 1.8952\n",
      "  52900/ 200000: 2.3755\n",
      "  53000/ 200000: 2.4386\n",
      "  53100/ 200000: 1.8994\n",
      "  53200/ 200000: 1.9266\n",
      "  53300/ 200000: 2.0912\n",
      "  53400/ 200000: 2.4098\n",
      "  53500/ 200000: 1.7981\n",
      "  53600/ 200000: 2.3575\n",
      "  53700/ 200000: 2.2395\n",
      "  53800/ 200000: 1.9958\n",
      "  53900/ 200000: 2.0718\n",
      "  54000/ 200000: 2.2080\n",
      "  54100/ 200000: 2.2155\n",
      "  54200/ 200000: 2.0922\n",
      "  54300/ 200000: 2.1032\n",
      "  54400/ 200000: 2.1113\n",
      "  54500/ 200000: 2.3444\n",
      "  54600/ 200000: 1.7128\n",
      "  54700/ 200000: 2.1768\n",
      "  54800/ 200000: 2.1615\n",
      "  54900/ 200000: 2.0295\n",
      "  55000/ 200000: 1.9875\n",
      "  55100/ 200000: 2.0754\n",
      "  55200/ 200000: 2.3546\n",
      "  55300/ 200000: 2.2258\n",
      "  55400/ 200000: 2.0513\n",
      "  55500/ 200000: 2.1578\n",
      "  55600/ 200000: 2.0882\n",
      "  55700/ 200000: 2.2873\n",
      "  55800/ 200000: 2.0978\n",
      "  55900/ 200000: 2.1635\n",
      "  56000/ 200000: 2.0683\n",
      "  56100/ 200000: 2.1050\n",
      "  56200/ 200000: 2.1414\n",
      "  56300/ 200000: 2.3122\n",
      "  56400/ 200000: 2.4126\n",
      "  56500/ 200000: 2.1738\n",
      "  56600/ 200000: 2.2408\n",
      "  56700/ 200000: 2.7539\n",
      "  56800/ 200000: 2.1131\n",
      "  56900/ 200000: 2.1206\n",
      "  57000/ 200000: 1.7810\n",
      "  57100/ 200000: 1.9856\n",
      "  57200/ 200000: 2.0316\n",
      "  57300/ 200000: 2.0837\n",
      "  57400/ 200000: 2.3467\n",
      "  57500/ 200000: 1.9611\n",
      "  57600/ 200000: 1.9689\n",
      "  57700/ 200000: 2.2851\n",
      "  57800/ 200000: 2.1971\n",
      "  57900/ 200000: 2.1969\n",
      "  58000/ 200000: 1.6859\n",
      "  58100/ 200000: 2.2591\n",
      "  58200/ 200000: 2.4252\n",
      "  58300/ 200000: 2.0767\n",
      "  58400/ 200000: 2.0923\n",
      "  58500/ 200000: 2.2304\n",
      "  58600/ 200000: 2.3081\n",
      "  58700/ 200000: 1.9781\n",
      "  58800/ 200000: 1.9121\n",
      "  58900/ 200000: 2.2113\n",
      "  59000/ 200000: 2.3786\n",
      "  59100/ 200000: 1.9980\n",
      "  59200/ 200000: 2.0418\n",
      "  59300/ 200000: 2.1240\n",
      "  59400/ 200000: 1.9825\n",
      "  59500/ 200000: 2.1107\n",
      "  59600/ 200000: 2.6724\n",
      "  59700/ 200000: 2.1286\n",
      "  59800/ 200000: 2.2106\n",
      "  59900/ 200000: 2.0057\n",
      "  60000/ 200000: 2.4255\n",
      "  60100/ 200000: 2.2457\n",
      "  60200/ 200000: 2.0359\n",
      "  60300/ 200000: 2.4044\n",
      "  60400/ 200000: 1.8555\n",
      "  60500/ 200000: 2.3727\n",
      "  60600/ 200000: 2.1193\n",
      "  60700/ 200000: 2.3565\n",
      "  60800/ 200000: 2.2969\n",
      "  60900/ 200000: 2.2750\n",
      "  61000/ 200000: 2.3382\n",
      "  61100/ 200000: 2.3749\n",
      "  61200/ 200000: 1.9459\n",
      "  61300/ 200000: 1.9047\n",
      "  61400/ 200000: 2.4162\n",
      "  61500/ 200000: 2.8654\n",
      "  61600/ 200000: 2.5689\n",
      "  61700/ 200000: 2.2184\n",
      "  61800/ 200000: 2.2122\n",
      "  61900/ 200000: 2.2411\n",
      "  62000/ 200000: 2.5512\n",
      "  62100/ 200000: 2.0632\n",
      "  62200/ 200000: 2.0085\n",
      "  62300/ 200000: 2.1544\n",
      "  62400/ 200000: 2.3649\n",
      "  62500/ 200000: 2.0452\n",
      "  62600/ 200000: 2.1119\n",
      "  62700/ 200000: 2.5744\n",
      "  62800/ 200000: 1.9767\n",
      "  62900/ 200000: 2.1683\n",
      "  63000/ 200000: 2.1068\n",
      "  63100/ 200000: 2.0473\n",
      "  63200/ 200000: 2.5568\n",
      "  63300/ 200000: 1.9867\n",
      "  63400/ 200000: 2.2809\n",
      "  63500/ 200000: 2.1774\n",
      "  63600/ 200000: 2.2142\n",
      "  63700/ 200000: 1.9061\n",
      "  63800/ 200000: 1.9941\n",
      "  63900/ 200000: 2.2941\n",
      "  64000/ 200000: 2.1824\n",
      "  64100/ 200000: 2.0844\n",
      "  64200/ 200000: 2.0333\n",
      "  64300/ 200000: 2.3879\n",
      "  64400/ 200000: 1.9911\n",
      "  64500/ 200000: 2.1772\n",
      "  64600/ 200000: 1.9286\n",
      "  64700/ 200000: 2.2876\n",
      "  64800/ 200000: 1.9240\n",
      "  64900/ 200000: 2.3333\n",
      "  65000/ 200000: 1.9920\n",
      "  65100/ 200000: 2.8649\n",
      "  65200/ 200000: 2.2041\n",
      "  65300/ 200000: 2.4764\n",
      "  65400/ 200000: 2.4178\n",
      "  65500/ 200000: 2.3014\n",
      "  65600/ 200000: 2.5698\n",
      "  65700/ 200000: 1.9263\n",
      "  65800/ 200000: 2.1619\n",
      "  65900/ 200000: 2.4409\n",
      "  66000/ 200000: 2.5275\n",
      "  66100/ 200000: 2.4731\n",
      "  66200/ 200000: 1.8363\n",
      "  66300/ 200000: 1.9002\n",
      "  66400/ 200000: 2.5748\n",
      "  66500/ 200000: 2.0893\n",
      "  66600/ 200000: 2.3447\n",
      "  66700/ 200000: 2.0776\n",
      "  66800/ 200000: 2.5337\n",
      "  66900/ 200000: 2.0037\n",
      "  67000/ 200000: 2.4497\n",
      "  67100/ 200000: 2.3830\n",
      "  67200/ 200000: 2.6041\n",
      "  67300/ 200000: 2.5137\n",
      "  67400/ 200000: 1.8880\n",
      "  67500/ 200000: 2.1539\n",
      "  67600/ 200000: 1.8618\n",
      "  67700/ 200000: 2.0568\n",
      "  67800/ 200000: 1.8483\n",
      "  67900/ 200000: 2.2769\n",
      "  68000/ 200000: 1.9225\n",
      "  68100/ 200000: 2.1713\n",
      "  68200/ 200000: 2.0684\n",
      "  68300/ 200000: 1.8832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  68400/ 200000: 2.6331\n",
      "  68500/ 200000: 1.9876\n",
      "  68600/ 200000: 2.1975\n",
      "  68700/ 200000: 2.2786\n",
      "  68800/ 200000: 2.3742\n",
      "  68900/ 200000: 2.2400\n",
      "  69000/ 200000: 2.1203\n",
      "  69100/ 200000: 1.9540\n",
      "  69200/ 200000: 2.0505\n",
      "  69300/ 200000: 2.1415\n",
      "  69400/ 200000: 2.4405\n",
      "  69500/ 200000: 2.2747\n",
      "  69600/ 200000: 2.2517\n",
      "  69700/ 200000: 2.1068\n",
      "  69800/ 200000: 2.0899\n",
      "  69900/ 200000: 2.1837\n",
      "  70000/ 200000: 2.0057\n",
      "  70100/ 200000: 2.6347\n",
      "  70200/ 200000: 2.3201\n",
      "  70300/ 200000: 2.4894\n",
      "  70400/ 200000: 2.2092\n",
      "  70500/ 200000: 2.2395\n",
      "  70600/ 200000: 1.9107\n",
      "  70700/ 200000: 2.7185\n",
      "  70800/ 200000: 1.6477\n",
      "  70900/ 200000: 1.6637\n",
      "  71000/ 200000: 2.2256\n",
      "  71100/ 200000: 2.3386\n",
      "  71200/ 200000: 2.4687\n",
      "  71300/ 200000: 2.0119\n",
      "  71400/ 200000: 2.3510\n",
      "  71500/ 200000: 2.1131\n",
      "  71600/ 200000: 2.2221\n",
      "  71700/ 200000: 1.8751\n",
      "  71800/ 200000: 1.8228\n",
      "  71900/ 200000: 2.3916\n",
      "  72000/ 200000: 2.5478\n",
      "  72100/ 200000: 2.1471\n",
      "  72200/ 200000: 2.0937\n",
      "  72300/ 200000: 2.4610\n",
      "  72400/ 200000: 1.9859\n",
      "  72500/ 200000: 1.9895\n",
      "  72600/ 200000: 2.0940\n",
      "  72700/ 200000: 1.8997\n",
      "  72800/ 200000: 2.3871\n",
      "  72900/ 200000: 2.3149\n",
      "  73000/ 200000: 2.4275\n",
      "  73100/ 200000: 2.4928\n",
      "  73200/ 200000: 1.9970\n",
      "  73300/ 200000: 2.0179\n",
      "  73400/ 200000: 1.9362\n",
      "  73500/ 200000: 2.3452\n",
      "  73600/ 200000: 1.9026\n",
      "  73700/ 200000: 2.0944\n",
      "  73800/ 200000: 2.0913\n",
      "  73900/ 200000: 1.8283\n",
      "  74000/ 200000: 1.7900\n",
      "  74100/ 200000: 2.1330\n",
      "  74200/ 200000: 2.0543\n",
      "  74300/ 200000: 1.8502\n",
      "  74400/ 200000: 2.4616\n",
      "  74500/ 200000: 1.8820\n",
      "  74600/ 200000: 1.6135\n",
      "  74700/ 200000: 2.1909\n",
      "  74800/ 200000: 2.3099\n",
      "  74900/ 200000: 2.1742\n",
      "  75000/ 200000: 2.4472\n",
      "  75100/ 200000: 1.9940\n",
      "  75200/ 200000: 2.3454\n",
      "  75300/ 200000: 2.0943\n",
      "  75400/ 200000: 2.1527\n",
      "  75500/ 200000: 1.8093\n",
      "  75600/ 200000: 2.0315\n",
      "  75700/ 200000: 2.6974\n",
      "  75800/ 200000: 2.1938\n",
      "  75900/ 200000: 2.2144\n",
      "  76000/ 200000: 1.7638\n",
      "  76100/ 200000: 2.0719\n",
      "  76200/ 200000: 2.0840\n",
      "  76300/ 200000: 1.9932\n",
      "  76400/ 200000: 2.3243\n",
      "  76500/ 200000: 2.2563\n",
      "  76600/ 200000: 2.0339\n",
      "  76700/ 200000: 2.0479\n",
      "  76800/ 200000: 2.0700\n",
      "  76900/ 200000: 2.0409\n",
      "  77000/ 200000: 2.2598\n",
      "  77100/ 200000: 2.0986\n",
      "  77200/ 200000: 2.3803\n",
      "  77300/ 200000: 1.8587\n",
      "  77400/ 200000: 2.0616\n",
      "  77500/ 200000: 2.2172\n",
      "  77600/ 200000: 1.9591\n",
      "  77700/ 200000: 2.4010\n",
      "  77800/ 200000: 2.5103\n",
      "  77900/ 200000: 2.1988\n",
      "  78000/ 200000: 2.3467\n",
      "  78100/ 200000: 1.9108\n",
      "  78200/ 200000: 2.0923\n",
      "  78300/ 200000: 2.3612\n",
      "  78400/ 200000: 1.9785\n",
      "  78500/ 200000: 2.0858\n",
      "  78600/ 200000: 2.1517\n",
      "  78700/ 200000: 2.2071\n",
      "  78800/ 200000: 2.1150\n",
      "  78900/ 200000: 2.2172\n",
      "  79000/ 200000: 2.1597\n",
      "  79100/ 200000: 1.8361\n",
      "  79200/ 200000: 2.0200\n",
      "  79300/ 200000: 2.5173\n",
      "  79400/ 200000: 1.8495\n",
      "  79500/ 200000: 2.1228\n",
      "  79600/ 200000: 2.3019\n",
      "  79700/ 200000: 2.0049\n",
      "  79800/ 200000: 2.5261\n",
      "  79900/ 200000: 2.2598\n",
      "  80000/ 200000: 2.3406\n",
      "  80100/ 200000: 2.1250\n",
      "  80200/ 200000: 2.3951\n",
      "  80300/ 200000: 2.1121\n",
      "  80400/ 200000: 2.2324\n",
      "  80500/ 200000: 2.2492\n",
      "  80600/ 200000: 2.1960\n",
      "  80700/ 200000: 2.3343\n",
      "  80800/ 200000: 2.0055\n",
      "  80900/ 200000: 1.8996\n",
      "  81000/ 200000: 1.9796\n",
      "  81100/ 200000: 2.0684\n",
      "  81200/ 200000: 2.1742\n",
      "  81300/ 200000: 2.0066\n",
      "  81400/ 200000: 2.2441\n",
      "  81500/ 200000: 2.2415\n",
      "  81600/ 200000: 2.3214\n",
      "  81700/ 200000: 1.8483\n",
      "  81800/ 200000: 2.2168\n",
      "  81900/ 200000: 2.4155\n",
      "  82000/ 200000: 2.3132\n",
      "  82100/ 200000: 2.0360\n",
      "  82200/ 200000: 2.4582\n",
      "  82300/ 200000: 1.7770\n",
      "  82400/ 200000: 1.7250\n",
      "  82500/ 200000: 2.2450\n",
      "  82600/ 200000: 2.3396\n",
      "  82700/ 200000: 2.1866\n",
      "  82800/ 200000: 2.0765\n",
      "  82900/ 200000: 1.8475\n",
      "  83000/ 200000: 1.8264\n",
      "  83100/ 200000: 1.9682\n",
      "  83200/ 200000: 1.9031\n",
      "  83300/ 200000: 2.0536\n",
      "  83400/ 200000: 2.2333\n",
      "  83500/ 200000: 2.1576\n",
      "  83600/ 200000: 2.0889\n",
      "  83700/ 200000: 2.0948\n",
      "  83800/ 200000: 2.0211\n",
      "  83900/ 200000: 2.2281\n",
      "  84000/ 200000: 2.3801\n",
      "  84100/ 200000: 2.2787\n",
      "  84200/ 200000: 1.6561\n",
      "  84300/ 200000: 2.5234\n",
      "  84400/ 200000: 2.1216\n",
      "  84500/ 200000: 1.9656\n",
      "  84600/ 200000: 1.9445\n",
      "  84700/ 200000: 2.2376\n",
      "  84800/ 200000: 2.1270\n",
      "  84900/ 200000: 2.5751\n",
      "  85000/ 200000: 2.1502\n",
      "  85100/ 200000: 2.1245\n",
      "  85200/ 200000: 1.9399\n",
      "  85300/ 200000: 2.3172\n",
      "  85400/ 200000: 2.5344\n",
      "  85500/ 200000: 1.9976\n",
      "  85600/ 200000: 2.2100\n",
      "  85700/ 200000: 1.6215\n",
      "  85800/ 200000: 1.8857\n",
      "  85900/ 200000: 2.2664\n",
      "  86000/ 200000: 2.1757\n",
      "  86100/ 200000: 2.3300\n",
      "  86200/ 200000: 1.9423\n",
      "  86300/ 200000: 2.3362\n",
      "  86400/ 200000: 2.1928\n",
      "  86500/ 200000: 2.3643\n",
      "  86600/ 200000: 2.0218\n",
      "  86700/ 200000: 2.3143\n",
      "  86800/ 200000: 2.6914\n",
      "  86900/ 200000: 1.9382\n",
      "  87000/ 200000: 2.1233\n",
      "  87100/ 200000: 1.7920\n",
      "  87200/ 200000: 2.0946\n",
      "  87300/ 200000: 1.9323\n",
      "  87400/ 200000: 1.8229\n",
      "  87500/ 200000: 2.2756\n",
      "  87600/ 200000: 1.9283\n",
      "  87700/ 200000: 2.0829\n",
      "  87800/ 200000: 2.3203\n",
      "  87900/ 200000: 2.5781\n",
      "  88000/ 200000: 2.3344\n",
      "  88100/ 200000: 2.0369\n",
      "  88200/ 200000: 1.7191\n",
      "  88300/ 200000: 1.9416\n",
      "  88400/ 200000: 2.0845\n",
      "  88500/ 200000: 2.1566\n",
      "  88600/ 200000: 2.3363\n",
      "  88700/ 200000: 2.2081\n",
      "  88800/ 200000: 2.1281\n",
      "  88900/ 200000: 1.8126\n",
      "  89000/ 200000: 2.1894\n",
      "  89100/ 200000: 2.5615\n",
      "  89200/ 200000: 2.3914\n",
      "  89300/ 200000: 2.6810\n",
      "  89400/ 200000: 2.1128\n",
      "  89500/ 200000: 2.1284\n",
      "  89600/ 200000: 2.2814\n",
      "  89700/ 200000: 2.2618\n",
      "  89800/ 200000: 1.6826\n",
      "  89900/ 200000: 2.1987\n",
      "  90000/ 200000: 2.1520\n",
      "  90100/ 200000: 1.9962\n",
      "  90200/ 200000: 2.3034\n",
      "  90300/ 200000: 1.7826\n",
      "  90400/ 200000: 2.3269\n",
      "  90500/ 200000: 2.7964\n",
      "  90600/ 200000: 2.3261\n",
      "  90700/ 200000: 2.2942\n",
      "  90800/ 200000: 2.4684\n",
      "  90900/ 200000: 2.0287\n",
      "  91000/ 200000: 1.9368\n",
      "  91100/ 200000: 1.8602\n",
      "  91200/ 200000: 2.2119\n",
      "  91300/ 200000: 2.6316\n",
      "  91400/ 200000: 2.1128\n",
      "  91500/ 200000: 2.0740\n",
      "  91600/ 200000: 2.1566\n",
      "  91700/ 200000: 2.7070\n",
      "  91800/ 200000: 2.2470\n",
      "  91900/ 200000: 2.1445\n",
      "  92000/ 200000: 2.4363\n",
      "  92100/ 200000: 1.8192\n",
      "  92200/ 200000: 2.2324\n",
      "  92300/ 200000: 1.9538\n",
      "  92400/ 200000: 2.2055\n",
      "  92500/ 200000: 2.4430\n",
      "  92600/ 200000: 2.1701\n",
      "  92700/ 200000: 2.2208\n",
      "  92800/ 200000: 1.9912\n",
      "  92900/ 200000: 1.9366\n",
      "  93000/ 200000: 1.6899\n",
      "  93100/ 200000: 1.9336\n",
      "  93200/ 200000: 2.0255\n",
      "  93300/ 200000: 2.6237\n",
      "  93400/ 200000: 2.1684\n",
      "  93500/ 200000: 2.4686\n",
      "  93600/ 200000: 2.1631\n",
      "  93700/ 200000: 2.4364\n",
      "  93800/ 200000: 2.0221\n",
      "  93900/ 200000: 2.3982\n",
      "  94000/ 200000: 1.9293\n",
      "  94100/ 200000: 2.0008\n",
      "  94200/ 200000: 1.9722\n",
      "  94300/ 200000: 2.3462\n",
      "  94400/ 200000: 2.3466\n",
      "  94500/ 200000: 2.4447\n",
      "  94600/ 200000: 1.8933\n",
      "  94700/ 200000: 2.3054\n",
      "  94800/ 200000: 2.1045\n",
      "  94900/ 200000: 2.1093\n",
      "  95000/ 200000: 1.9833\n",
      "  95100/ 200000: 1.9503\n",
      "  95200/ 200000: 2.2277\n",
      "  95300/ 200000: 2.1921\n",
      "  95400/ 200000: 2.2191\n",
      "  95500/ 200000: 2.1305\n",
      "  95600/ 200000: 2.1951\n",
      "  95700/ 200000: 2.2215\n",
      "  95800/ 200000: 2.2342\n",
      "  95900/ 200000: 2.4781\n",
      "  96000/ 200000: 1.9445\n",
      "  96100/ 200000: 1.8442\n",
      "  96200/ 200000: 2.6395\n",
      "  96300/ 200000: 2.2483\n",
      "  96400/ 200000: 2.1882\n",
      "  96500/ 200000: 2.1770\n",
      "  96600/ 200000: 2.1101\n",
      "  96700/ 200000: 2.2500\n",
      "  96800/ 200000: 2.3487\n",
      "  96900/ 200000: 2.4185\n",
      "  97000/ 200000: 2.3310\n",
      "  97100/ 200000: 2.4548\n",
      "  97200/ 200000: 1.8484\n",
      "  97300/ 200000: 2.1498\n",
      "  97400/ 200000: 1.9858\n",
      "  97500/ 200000: 2.3613\n",
      "  97600/ 200000: 1.8845\n",
      "  97700/ 200000: 2.4873\n",
      "  97800/ 200000: 2.4521\n",
      "  97900/ 200000: 2.1168\n",
      "  98000/ 200000: 2.0180\n",
      "  98100/ 200000: 2.2578\n",
      "  98200/ 200000: 1.9331\n",
      "  98300/ 200000: 2.0308\n",
      "  98400/ 200000: 1.9767\n",
      "  98500/ 200000: 1.9789\n",
      "  98600/ 200000: 2.3987\n",
      "  98700/ 200000: 2.2910\n",
      "  98800/ 200000: 1.9674\n",
      "  98900/ 200000: 2.4792\n",
      "  99000/ 200000: 2.0401\n",
      "  99100/ 200000: 1.9222\n",
      "  99200/ 200000: 1.9463\n",
      "  99300/ 200000: 2.0622\n",
      "  99400/ 200000: 2.1774\n",
      "  99500/ 200000: 2.1163\n",
      "  99600/ 200000: 2.0204\n",
      "  99700/ 200000: 2.1654\n",
      "  99800/ 200000: 2.2323\n",
      "  99900/ 200000: 2.0264\n",
      " 100000/ 200000: 1.9231\n",
      " 100100/ 200000: 2.0610\n",
      " 100200/ 200000: 2.2943\n",
      " 100300/ 200000: 2.1291\n",
      " 100400/ 200000: 2.1516\n",
      " 100500/ 200000: 2.2739\n",
      " 100600/ 200000: 2.6741\n",
      " 100700/ 200000: 2.2394\n",
      " 100800/ 200000: 2.1616\n",
      " 100900/ 200000: 2.1620\n",
      " 101000/ 200000: 1.7117\n",
      " 101100/ 200000: 2.3996\n",
      " 101200/ 200000: 2.1738\n",
      " 101300/ 200000: 2.0647\n",
      " 101400/ 200000: 2.1687\n",
      " 101500/ 200000: 1.9062\n",
      " 101600/ 200000: 2.3052\n",
      " 101700/ 200000: 2.1875\n",
      " 101800/ 200000: 1.8149\n",
      " 101900/ 200000: 1.9525\n",
      " 102000/ 200000: 2.3003\n",
      " 102100/ 200000: 2.1691\n",
      " 102200/ 200000: 2.1371\n",
      " 102300/ 200000: 2.1177\n",
      " 102400/ 200000: 2.1018\n",
      " 102500/ 200000: 2.3217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 102600/ 200000: 2.0913\n",
      " 102700/ 200000: 2.1816\n",
      " 102800/ 200000: 2.5283\n",
      " 102900/ 200000: 2.0085\n",
      " 103000/ 200000: 2.1612\n",
      " 103100/ 200000: 2.2091\n",
      " 103200/ 200000: 2.3000\n",
      " 103300/ 200000: 2.0070\n",
      " 103400/ 200000: 2.2988\n",
      " 103500/ 200000: 2.1439\n",
      " 103600/ 200000: 1.9051\n",
      " 103700/ 200000: 2.3110\n",
      " 103800/ 200000: 2.5280\n",
      " 103900/ 200000: 2.0731\n",
      " 104000/ 200000: 2.2847\n",
      " 104100/ 200000: 2.3257\n",
      " 104200/ 200000: 2.0463\n",
      " 104300/ 200000: 2.0709\n",
      " 104400/ 200000: 2.0111\n",
      " 104500/ 200000: 1.9491\n",
      " 104600/ 200000: 2.8621\n",
      " 104700/ 200000: 2.0824\n",
      " 104800/ 200000: 1.9736\n",
      " 104900/ 200000: 2.0452\n",
      " 105000/ 200000: 1.9835\n",
      " 105100/ 200000: 2.1710\n",
      " 105200/ 200000: 2.1440\n",
      " 105300/ 200000: 2.2510\n",
      " 105400/ 200000: 1.8797\n",
      " 105500/ 200000: 2.0458\n",
      " 105600/ 200000: 2.0253\n",
      " 105700/ 200000: 2.1690\n",
      " 105800/ 200000: 2.2340\n",
      " 105900/ 200000: 1.9634\n",
      " 106000/ 200000: 2.2926\n",
      " 106100/ 200000: 1.8802\n",
      " 106200/ 200000: 1.8477\n",
      " 106300/ 200000: 2.1778\n",
      " 106400/ 200000: 2.3443\n",
      " 106500/ 200000: 2.2146\n",
      " 106600/ 200000: 2.0521\n",
      " 106700/ 200000: 1.9932\n",
      " 106800/ 200000: 2.6224\n",
      " 106900/ 200000: 1.9444\n",
      " 107000/ 200000: 2.0456\n",
      " 107100/ 200000: 2.0805\n",
      " 107200/ 200000: 1.9620\n",
      " 107300/ 200000: 1.8889\n",
      " 107400/ 200000: 2.0164\n",
      " 107500/ 200000: 1.7077\n",
      " 107600/ 200000: 2.1424\n",
      " 107700/ 200000: 2.0644\n",
      " 107800/ 200000: 1.8392\n",
      " 107900/ 200000: 1.9897\n",
      " 108000/ 200000: 2.0109\n",
      " 108100/ 200000: 2.1712\n",
      " 108200/ 200000: 2.2379\n",
      " 108300/ 200000: 2.2334\n",
      " 108400/ 200000: 2.0730\n",
      " 108500/ 200000: 2.0454\n",
      " 108600/ 200000: 2.0211\n",
      " 108700/ 200000: 2.6461\n",
      " 108800/ 200000: 1.9180\n",
      " 108900/ 200000: 2.0634\n",
      " 109000/ 200000: 2.2879\n",
      " 109100/ 200000: 1.7737\n",
      " 109200/ 200000: 2.2459\n",
      " 109300/ 200000: 2.2176\n",
      " 109400/ 200000: 2.0579\n",
      " 109500/ 200000: 1.9888\n",
      " 109600/ 200000: 2.3593\n",
      " 109700/ 200000: 2.1544\n",
      " 109800/ 200000: 1.9698\n",
      " 109900/ 200000: 2.3756\n",
      " 110000/ 200000: 2.3624\n",
      " 110100/ 200000: 2.2079\n",
      " 110200/ 200000: 2.2745\n",
      " 110300/ 200000: 1.9425\n",
      " 110400/ 200000: 2.1594\n",
      " 110500/ 200000: 2.1592\n",
      " 110600/ 200000: 1.6485\n",
      " 110700/ 200000: 1.9456\n",
      " 110800/ 200000: 2.0917\n",
      " 110900/ 200000: 1.9419\n",
      " 111000/ 200000: 2.3110\n",
      " 111100/ 200000: 1.9884\n",
      " 111200/ 200000: 2.2512\n",
      " 111300/ 200000: 2.6044\n",
      " 111400/ 200000: 2.0341\n",
      " 111500/ 200000: 2.1136\n",
      " 111600/ 200000: 2.8265\n",
      " 111700/ 200000: 1.9205\n",
      " 111800/ 200000: 2.1034\n",
      " 111900/ 200000: 1.9203\n",
      " 112000/ 200000: 2.0292\n",
      " 112100/ 200000: 2.2110\n",
      " 112200/ 200000: 2.0284\n",
      " 112300/ 200000: 2.1554\n",
      " 112400/ 200000: 1.7828\n",
      " 112500/ 200000: 2.1403\n",
      " 112600/ 200000: 1.7732\n",
      " 112700/ 200000: 2.2537\n",
      " 112800/ 200000: 2.0781\n",
      " 112900/ 200000: 2.1989\n",
      " 113000/ 200000: 2.3108\n",
      " 113100/ 200000: 2.0665\n",
      " 113200/ 200000: 2.0171\n",
      " 113300/ 200000: 2.0021\n",
      " 113400/ 200000: 2.0367\n",
      " 113500/ 200000: 2.6357\n",
      " 113600/ 200000: 2.0025\n",
      " 113700/ 200000: 2.0484\n",
      " 113800/ 200000: 2.0971\n",
      " 113900/ 200000: 2.1319\n",
      " 114000/ 200000: 2.0714\n",
      " 114100/ 200000: 2.6650\n",
      " 114200/ 200000: 2.1417\n",
      " 114300/ 200000: 2.1203\n",
      " 114400/ 200000: 1.9225\n",
      " 114500/ 200000: 2.1547\n",
      " 114600/ 200000: 2.3368\n",
      " 114700/ 200000: 2.3501\n",
      " 114800/ 200000: 2.2984\n",
      " 114900/ 200000: 2.0623\n",
      " 115000/ 200000: 2.2127\n",
      " 115100/ 200000: 2.4833\n",
      " 115200/ 200000: 2.3968\n",
      " 115300/ 200000: 1.9555\n",
      " 115400/ 200000: 2.1506\n",
      " 115500/ 200000: 1.8205\n",
      " 115600/ 200000: 2.4001\n",
      " 115700/ 200000: 2.0574\n",
      " 115800/ 200000: 2.0382\n",
      " 115900/ 200000: 2.1800\n",
      " 116000/ 200000: 2.1203\n",
      " 116100/ 200000: 2.0900\n",
      " 116200/ 200000: 2.4532\n",
      " 116300/ 200000: 2.3131\n",
      " 116400/ 200000: 2.7040\n",
      " 116500/ 200000: 2.1953\n",
      " 116600/ 200000: 2.2712\n",
      " 116700/ 200000: 2.4475\n",
      " 116800/ 200000: 1.8982\n",
      " 116900/ 200000: 1.9410\n",
      " 117000/ 200000: 2.2923\n",
      " 117100/ 200000: 2.1106\n",
      " 117200/ 200000: 1.6834\n",
      " 117300/ 200000: 1.9005\n",
      " 117400/ 200000: 2.3593\n",
      " 117500/ 200000: 2.0205\n",
      " 117600/ 200000: 2.3551\n",
      " 117700/ 200000: 2.0341\n",
      " 117800/ 200000: 2.1133\n",
      " 117900/ 200000: 2.2450\n",
      " 118000/ 200000: 2.3061\n",
      " 118100/ 200000: 2.1233\n",
      " 118200/ 200000: 2.1863\n",
      " 118300/ 200000: 2.2244\n",
      " 118400/ 200000: 2.3342\n",
      " 118500/ 200000: 2.0608\n",
      " 118600/ 200000: 2.0025\n",
      " 118700/ 200000: 2.3548\n",
      " 118800/ 200000: 1.7979\n",
      " 118900/ 200000: 2.2694\n",
      " 119000/ 200000: 2.0800\n",
      " 119100/ 200000: 2.0830\n",
      " 119200/ 200000: 2.3037\n",
      " 119300/ 200000: 1.8183\n",
      " 119400/ 200000: 2.0483\n",
      " 119500/ 200000: 2.1124\n",
      " 119600/ 200000: 2.2725\n",
      " 119700/ 200000: 2.1152\n",
      " 119800/ 200000: 1.8746\n",
      " 119900/ 200000: 2.2219\n",
      " 120000/ 200000: 1.9875\n",
      " 120100/ 200000: 2.2789\n",
      " 120200/ 200000: 1.7911\n",
      " 120300/ 200000: 2.3664\n",
      " 120400/ 200000: 1.8680\n",
      " 120500/ 200000: 1.8851\n",
      " 120600/ 200000: 2.3251\n",
      " 120700/ 200000: 2.2573\n",
      " 120800/ 200000: 1.8978\n",
      " 120900/ 200000: 2.4453\n",
      " 121000/ 200000: 2.2489\n",
      " 121100/ 200000: 2.3610\n",
      " 121200/ 200000: 2.0835\n",
      " 121300/ 200000: 2.3582\n",
      " 121400/ 200000: 2.3941\n",
      " 121500/ 200000: 2.2391\n",
      " 121600/ 200000: 2.1012\n",
      " 121700/ 200000: 2.2561\n",
      " 121800/ 200000: 2.5390\n",
      " 121900/ 200000: 1.9885\n",
      " 122000/ 200000: 2.1209\n",
      " 122100/ 200000: 2.0583\n",
      " 122200/ 200000: 2.5242\n",
      " 122300/ 200000: 2.5360\n",
      " 122400/ 200000: 1.6780\n",
      " 122500/ 200000: 2.1112\n",
      " 122600/ 200000: 2.6277\n",
      " 122700/ 200000: 2.1216\n",
      " 122800/ 200000: 2.4307\n",
      " 122900/ 200000: 2.2206\n",
      " 123000/ 200000: 2.4766\n",
      " 123100/ 200000: 1.8844\n",
      " 123200/ 200000: 2.0755\n",
      " 123300/ 200000: 1.9919\n",
      " 123400/ 200000: 2.0794\n",
      " 123500/ 200000: 2.1336\n",
      " 123600/ 200000: 2.0281\n",
      " 123700/ 200000: 2.0272\n",
      " 123800/ 200000: 1.8109\n",
      " 123900/ 200000: 2.0322\n",
      " 124000/ 200000: 2.6012\n",
      " 124100/ 200000: 2.0323\n",
      " 124200/ 200000: 1.7499\n",
      " 124300/ 200000: 2.1685\n",
      " 124400/ 200000: 2.1944\n",
      " 124500/ 200000: 2.5320\n",
      " 124600/ 200000: 1.8466\n",
      " 124700/ 200000: 2.1848\n",
      " 124800/ 200000: 2.1892\n",
      " 124900/ 200000: 2.1137\n",
      " 125000/ 200000: 2.0295\n",
      " 125100/ 200000: 1.8836\n",
      " 125200/ 200000: 2.3039\n",
      " 125300/ 200000: 2.2553\n",
      " 125400/ 200000: 1.9453\n",
      " 125500/ 200000: 2.0492\n",
      " 125600/ 200000: 2.0097\n",
      " 125700/ 200000: 2.2981\n",
      " 125800/ 200000: 2.1773\n",
      " 125900/ 200000: 2.1043\n",
      " 126000/ 200000: 2.2057\n",
      " 126100/ 200000: 2.4839\n",
      " 126200/ 200000: 2.5537\n",
      " 126300/ 200000: 1.9299\n",
      " 126400/ 200000: 2.4916\n",
      " 126500/ 200000: 2.1596\n",
      " 126600/ 200000: 1.8552\n",
      " 126700/ 200000: 1.8170\n",
      " 126800/ 200000: 2.2144\n",
      " 126900/ 200000: 1.8961\n",
      " 127000/ 200000: 2.1463\n",
      " 127100/ 200000: 2.0602\n",
      " 127200/ 200000: 1.8848\n",
      " 127300/ 200000: 2.0639\n",
      " 127400/ 200000: 1.9478\n",
      " 127500/ 200000: 2.3828\n",
      " 127600/ 200000: 2.1503\n",
      " 127700/ 200000: 1.7905\n",
      " 127800/ 200000: 1.9385\n",
      " 127900/ 200000: 2.1567\n",
      " 128000/ 200000: 2.4910\n",
      " 128100/ 200000: 2.2212\n",
      " 128200/ 200000: 1.8820\n",
      " 128300/ 200000: 1.7025\n",
      " 128400/ 200000: 1.7805\n",
      " 128500/ 200000: 2.0133\n",
      " 128600/ 200000: 2.1814\n",
      " 128700/ 200000: 2.2648\n",
      " 128800/ 200000: 1.9986\n",
      " 128900/ 200000: 2.1676\n",
      " 129000/ 200000: 2.3360\n",
      " 129100/ 200000: 2.1360\n",
      " 129200/ 200000: 1.9623\n",
      " 129300/ 200000: 2.1954\n",
      " 129400/ 200000: 2.0685\n",
      " 129500/ 200000: 2.0841\n",
      " 129600/ 200000: 1.9246\n",
      " 129700/ 200000: 1.8978\n",
      " 129800/ 200000: 2.1080\n",
      " 129900/ 200000: 2.0448\n",
      " 130000/ 200000: 2.4462\n",
      " 130100/ 200000: 2.0478\n",
      " 130200/ 200000: 2.2377\n",
      " 130300/ 200000: 1.8581\n",
      " 130400/ 200000: 2.3703\n",
      " 130500/ 200000: 2.3605\n",
      " 130600/ 200000: 1.8327\n",
      " 130700/ 200000: 1.8881\n",
      " 130800/ 200000: 2.2711\n",
      " 130900/ 200000: 2.0275\n",
      " 131000/ 200000: 1.9045\n",
      " 131100/ 200000: 1.8563\n",
      " 131200/ 200000: 2.2029\n",
      " 131300/ 200000: 1.9996\n",
      " 131400/ 200000: 2.2308\n",
      " 131500/ 200000: 2.2614\n",
      " 131600/ 200000: 1.9272\n",
      " 131700/ 200000: 2.2307\n",
      " 131800/ 200000: 1.8089\n",
      " 131900/ 200000: 2.1283\n",
      " 132000/ 200000: 1.7807\n",
      " 132100/ 200000: 1.9792\n",
      " 132200/ 200000: 1.8166\n",
      " 132300/ 200000: 2.3551\n",
      " 132400/ 200000: 2.1311\n",
      " 132500/ 200000: 2.0136\n",
      " 132600/ 200000: 1.9874\n",
      " 132700/ 200000: 2.1131\n",
      " 132800/ 200000: 2.0576\n",
      " 132900/ 200000: 2.0622\n",
      " 133000/ 200000: 2.2508\n",
      " 133100/ 200000: 1.9691\n",
      " 133200/ 200000: 2.3468\n",
      " 133300/ 200000: 2.0578\n",
      " 133400/ 200000: 2.0904\n",
      " 133500/ 200000: 2.4421\n",
      " 133600/ 200000: 2.1849\n",
      " 133700/ 200000: 1.9401\n",
      " 133800/ 200000: 1.9097\n",
      " 133900/ 200000: 1.8139\n",
      " 134000/ 200000: 2.0703\n",
      " 134100/ 200000: 1.8262\n",
      " 134200/ 200000: 2.0615\n",
      " 134300/ 200000: 1.8900\n",
      " 134400/ 200000: 2.0024\n",
      " 134500/ 200000: 2.3945\n",
      " 134600/ 200000: 1.9783\n",
      " 134700/ 200000: 2.0024\n",
      " 134800/ 200000: 1.9598\n",
      " 134900/ 200000: 1.8454\n",
      " 135000/ 200000: 2.0327\n",
      " 135100/ 200000: 2.2632\n",
      " 135200/ 200000: 2.1922\n",
      " 135300/ 200000: 2.1734\n",
      " 135400/ 200000: 1.6966\n",
      " 135500/ 200000: 1.7888\n",
      " 135600/ 200000: 2.2980\n",
      " 135700/ 200000: 2.1067\n",
      " 135800/ 200000: 2.2802\n",
      " 135900/ 200000: 2.1608\n",
      " 136000/ 200000: 1.9435\n",
      " 136100/ 200000: 1.8390\n",
      " 136200/ 200000: 2.2524\n",
      " 136300/ 200000: 2.5706\n",
      " 136400/ 200000: 1.7580\n",
      " 136500/ 200000: 2.1750\n",
      " 136600/ 200000: 2.0655\n",
      " 136700/ 200000: 2.1686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 136800/ 200000: 1.6282\n",
      " 136900/ 200000: 1.8012\n",
      " 137000/ 200000: 2.0187\n",
      " 137100/ 200000: 1.8050\n",
      " 137200/ 200000: 2.0770\n",
      " 137300/ 200000: 2.3701\n",
      " 137400/ 200000: 2.0706\n",
      " 137500/ 200000: 2.1706\n",
      " 137600/ 200000: 2.4072\n",
      " 137700/ 200000: 2.0043\n",
      " 137800/ 200000: 2.3084\n",
      " 137900/ 200000: 2.2099\n",
      " 138000/ 200000: 2.1197\n",
      " 138100/ 200000: 2.4568\n",
      " 138200/ 200000: 2.3653\n",
      " 138300/ 200000: 2.1701\n",
      " 138400/ 200000: 2.2289\n",
      " 138500/ 200000: 2.0713\n",
      " 138600/ 200000: 2.3906\n",
      " 138700/ 200000: 2.2139\n",
      " 138800/ 200000: 2.0395\n",
      " 138900/ 200000: 2.6464\n",
      " 139000/ 200000: 1.9552\n",
      " 139100/ 200000: 2.0621\n",
      " 139200/ 200000: 1.9938\n",
      " 139300/ 200000: 2.0985\n",
      " 139400/ 200000: 2.2922\n",
      " 139500/ 200000: 1.8669\n",
      " 139600/ 200000: 2.0508\n",
      " 139700/ 200000: 2.0652\n",
      " 139800/ 200000: 2.0805\n",
      " 139900/ 200000: 2.0594\n",
      " 140000/ 200000: 2.3167\n",
      " 140100/ 200000: 2.3887\n",
      " 140200/ 200000: 1.7803\n",
      " 140300/ 200000: 1.9175\n",
      " 140400/ 200000: 1.9439\n",
      " 140500/ 200000: 2.0538\n",
      " 140600/ 200000: 1.9058\n",
      " 140700/ 200000: 2.2302\n",
      " 140800/ 200000: 2.1419\n",
      " 140900/ 200000: 2.2747\n",
      " 141000/ 200000: 1.8052\n",
      " 141100/ 200000: 1.6658\n",
      " 141200/ 200000: 1.8067\n",
      " 141300/ 200000: 2.1417\n",
      " 141400/ 200000: 1.6635\n",
      " 141500/ 200000: 2.0621\n",
      " 141600/ 200000: 2.1151\n",
      " 141700/ 200000: 1.8163\n",
      " 141800/ 200000: 2.1022\n",
      " 141900/ 200000: 1.8233\n",
      " 142000/ 200000: 2.0926\n",
      " 142100/ 200000: 2.0221\n",
      " 142200/ 200000: 2.3169\n",
      " 142300/ 200000: 2.3794\n",
      " 142400/ 200000: 2.0143\n",
      " 142500/ 200000: 2.1148\n",
      " 142600/ 200000: 2.0172\n",
      " 142700/ 200000: 2.4211\n",
      " 142800/ 200000: 2.2482\n",
      " 142900/ 200000: 2.3127\n",
      " 143000/ 200000: 2.2514\n",
      " 143100/ 200000: 1.9226\n",
      " 143200/ 200000: 2.1079\n",
      " 143300/ 200000: 2.0024\n",
      " 143400/ 200000: 2.2154\n",
      " 143500/ 200000: 1.8950\n",
      " 143600/ 200000: 1.9178\n",
      " 143700/ 200000: 2.3866\n",
      " 143800/ 200000: 2.4671\n",
      " 143900/ 200000: 2.2350\n",
      " 144000/ 200000: 2.0713\n",
      " 144100/ 200000: 2.4472\n",
      " 144200/ 200000: 1.8164\n",
      " 144300/ 200000: 1.8415\n",
      " 144400/ 200000: 2.2176\n",
      " 144500/ 200000: 2.2618\n",
      " 144600/ 200000: 2.8459\n",
      " 144700/ 200000: 1.9465\n",
      " 144800/ 200000: 1.9848\n",
      " 144900/ 200000: 2.1177\n",
      " 145000/ 200000: 2.1351\n",
      " 145100/ 200000: 2.1518\n",
      " 145200/ 200000: 2.4701\n",
      " 145300/ 200000: 1.9635\n",
      " 145400/ 200000: 2.0431\n",
      " 145500/ 200000: 1.8645\n",
      " 145600/ 200000: 1.8405\n",
      " 145700/ 200000: 2.2017\n",
      " 145800/ 200000: 2.2186\n",
      " 145900/ 200000: 2.1077\n",
      " 146000/ 200000: 2.2308\n",
      " 146100/ 200000: 2.0926\n",
      " 146200/ 200000: 2.0175\n",
      " 146300/ 200000: 2.4060\n",
      " 146400/ 200000: 2.2774\n",
      " 146500/ 200000: 1.9694\n",
      " 146600/ 200000: 1.7485\n",
      " 146700/ 200000: 1.9954\n",
      " 146800/ 200000: 2.3909\n",
      " 146900/ 200000: 1.9814\n",
      " 147000/ 200000: 2.2244\n",
      " 147100/ 200000: 2.2030\n",
      " 147200/ 200000: 2.1815\n",
      " 147300/ 200000: 2.1240\n",
      " 147400/ 200000: 1.7949\n",
      " 147500/ 200000: 2.0980\n",
      " 147600/ 200000: 1.9299\n",
      " 147700/ 200000: 2.0270\n",
      " 147800/ 200000: 2.1716\n",
      " 147900/ 200000: 2.2342\n",
      " 148000/ 200000: 2.3696\n",
      " 148100/ 200000: 2.2931\n",
      " 148200/ 200000: 1.8780\n",
      " 148300/ 200000: 2.3176\n",
      " 148400/ 200000: 2.0422\n",
      " 148500/ 200000: 2.1391\n",
      " 148600/ 200000: 1.9647\n",
      " 148700/ 200000: 1.9370\n",
      " 148800/ 200000: 2.7144\n",
      " 148900/ 200000: 1.9068\n",
      " 149000/ 200000: 2.2531\n",
      " 149100/ 200000: 2.2270\n",
      " 149200/ 200000: 2.1485\n",
      " 149300/ 200000: 2.3295\n",
      " 149400/ 200000: 1.9174\n",
      " 149500/ 200000: 1.8488\n",
      " 149600/ 200000: 2.0328\n",
      " 149700/ 200000: 2.1168\n",
      " 149800/ 200000: 2.2511\n",
      " 149900/ 200000: 1.9401\n",
      " 150000/ 200000: 2.1497\n",
      " 150100/ 200000: 2.2100\n",
      " 150200/ 200000: 1.7302\n",
      " 150300/ 200000: 2.2610\n",
      " 150400/ 200000: 1.9529\n",
      " 150500/ 200000: 1.9325\n",
      " 150600/ 200000: 2.1475\n",
      " 150700/ 200000: 1.9897\n",
      " 150800/ 200000: 2.4009\n",
      " 150900/ 200000: 1.9932\n",
      " 151000/ 200000: 2.3102\n",
      " 151100/ 200000: 1.6226\n",
      " 151200/ 200000: 1.8685\n",
      " 151300/ 200000: 2.1959\n",
      " 151400/ 200000: 1.9731\n",
      " 151500/ 200000: 2.1197\n",
      " 151600/ 200000: 1.7780\n",
      " 151700/ 200000: 1.9941\n",
      " 151800/ 200000: 2.3270\n",
      " 151900/ 200000: 2.0724\n",
      " 152000/ 200000: 1.9878\n",
      " 152100/ 200000: 2.2313\n",
      " 152200/ 200000: 2.0623\n",
      " 152300/ 200000: 1.9862\n",
      " 152400/ 200000: 2.0684\n",
      " 152500/ 200000: 2.0849\n",
      " 152600/ 200000: 2.4948\n",
      " 152700/ 200000: 1.9233\n",
      " 152800/ 200000: 2.2432\n",
      " 152900/ 200000: 2.2200\n",
      " 153000/ 200000: 2.2216\n",
      " 153100/ 200000: 2.4332\n",
      " 153200/ 200000: 1.9664\n",
      " 153300/ 200000: 1.8150\n",
      " 153400/ 200000: 2.2469\n",
      " 153500/ 200000: 1.8197\n",
      " 153600/ 200000: 2.2219\n",
      " 153700/ 200000: 2.2013\n",
      " 153800/ 200000: 1.7248\n",
      " 153900/ 200000: 1.9637\n",
      " 154000/ 200000: 2.2826\n",
      " 154100/ 200000: 2.2134\n",
      " 154200/ 200000: 2.2659\n",
      " 154300/ 200000: 1.9870\n",
      " 154400/ 200000: 1.9155\n",
      " 154500/ 200000: 2.0373\n",
      " 154600/ 200000: 1.9200\n",
      " 154700/ 200000: 1.7897\n",
      " 154800/ 200000: 2.3286\n",
      " 154900/ 200000: 2.0118\n",
      " 155000/ 200000: 2.0671\n",
      " 155100/ 200000: 1.6740\n",
      " 155200/ 200000: 1.4597\n",
      " 155300/ 200000: 2.2419\n",
      " 155400/ 200000: 1.9399\n",
      " 155500/ 200000: 2.1581\n",
      " 155600/ 200000: 2.1753\n",
      " 155700/ 200000: 2.0153\n",
      " 155800/ 200000: 2.1177\n",
      " 155900/ 200000: 2.0395\n",
      " 156000/ 200000: 1.9452\n",
      " 156100/ 200000: 1.9333\n",
      " 156200/ 200000: 2.0726\n",
      " 156300/ 200000: 1.9012\n",
      " 156400/ 200000: 2.0086\n",
      " 156500/ 200000: 2.0949\n",
      " 156600/ 200000: 1.9952\n",
      " 156700/ 200000: 1.8727\n",
      " 156800/ 200000: 2.1176\n",
      " 156900/ 200000: 2.2039\n",
      " 157000/ 200000: 2.1445\n",
      " 157100/ 200000: 1.7188\n",
      " 157200/ 200000: 1.6527\n",
      " 157300/ 200000: 2.0670\n",
      " 157400/ 200000: 2.1054\n",
      " 157500/ 200000: 1.9443\n",
      " 157600/ 200000: 2.5223\n",
      " 157700/ 200000: 2.3267\n",
      " 157800/ 200000: 2.2688\n",
      " 157900/ 200000: 1.7703\n",
      " 158000/ 200000: 1.9906\n",
      " 158100/ 200000: 1.7097\n",
      " 158200/ 200000: 2.0243\n",
      " 158300/ 200000: 2.7383\n",
      " 158400/ 200000: 2.1335\n",
      " 158500/ 200000: 1.9428\n",
      " 158600/ 200000: 2.1294\n",
      " 158700/ 200000: 2.0303\n",
      " 158800/ 200000: 1.9534\n",
      " 158900/ 200000: 2.1762\n",
      " 159000/ 200000: 2.1043\n",
      " 159100/ 200000: 2.0308\n",
      " 159200/ 200000: 2.1863\n",
      " 159300/ 200000: 2.0159\n",
      " 159400/ 200000: 2.1251\n",
      " 159500/ 200000: 2.1604\n",
      " 159600/ 200000: 2.4523\n",
      " 159700/ 200000: 2.4437\n",
      " 159800/ 200000: 2.2594\n",
      " 159900/ 200000: 2.3027\n",
      " 160000/ 200000: 1.9432\n",
      " 160100/ 200000: 1.7274\n",
      " 160200/ 200000: 2.1833\n",
      " 160300/ 200000: 1.9939\n",
      " 160400/ 200000: 1.9573\n",
      " 160500/ 200000: 2.2219\n",
      " 160600/ 200000: 2.5303\n",
      " 160700/ 200000: 1.6790\n",
      " 160800/ 200000: 1.8251\n",
      " 160900/ 200000: 2.1902\n",
      " 161000/ 200000: 2.1474\n",
      " 161100/ 200000: 1.8562\n",
      " 161200/ 200000: 1.7566\n",
      " 161300/ 200000: 2.0915\n",
      " 161400/ 200000: 2.2087\n",
      " 161500/ 200000: 2.3235\n",
      " 161600/ 200000: 2.6092\n",
      " 161700/ 200000: 2.2662\n",
      " 161800/ 200000: 1.9710\n",
      " 161900/ 200000: 2.2567\n",
      " 162000/ 200000: 1.8941\n",
      " 162100/ 200000: 1.8094\n",
      " 162200/ 200000: 2.0058\n",
      " 162300/ 200000: 2.0265\n",
      " 162400/ 200000: 2.1577\n",
      " 162500/ 200000: 2.0132\n",
      " 162600/ 200000: 2.1303\n",
      " 162700/ 200000: 2.2184\n",
      " 162800/ 200000: 2.0626\n",
      " 162900/ 200000: 2.2359\n",
      " 163000/ 200000: 2.1678\n",
      " 163100/ 200000: 2.3745\n",
      " 163200/ 200000: 2.2802\n",
      " 163300/ 200000: 2.2506\n",
      " 163400/ 200000: 2.1366\n",
      " 163500/ 200000: 2.1278\n",
      " 163600/ 200000: 1.9813\n",
      " 163700/ 200000: 1.9773\n",
      " 163800/ 200000: 1.8188\n",
      " 163900/ 200000: 2.0329\n",
      " 164000/ 200000: 2.2211\n",
      " 164100/ 200000: 2.4694\n",
      " 164200/ 200000: 2.3497\n",
      " 164300/ 200000: 2.0251\n",
      " 164400/ 200000: 2.3232\n",
      " 164500/ 200000: 2.0983\n",
      " 164600/ 200000: 1.9218\n",
      " 164700/ 200000: 2.1815\n",
      " 164800/ 200000: 2.4528\n",
      " 164900/ 200000: 2.3578\n",
      " 165000/ 200000: 2.6177\n",
      " 165100/ 200000: 2.3272\n",
      " 165200/ 200000: 2.1622\n",
      " 165300/ 200000: 1.9215\n",
      " 165400/ 200000: 1.7953\n",
      " 165500/ 200000: 2.3384\n",
      " 165600/ 200000: 2.1649\n",
      " 165700/ 200000: 1.8650\n",
      " 165800/ 200000: 2.1163\n",
      " 165900/ 200000: 2.0154\n",
      " 166000/ 200000: 2.3040\n",
      " 166100/ 200000: 2.2110\n",
      " 166200/ 200000: 2.0337\n",
      " 166300/ 200000: 2.0943\n",
      " 166400/ 200000: 1.9289\n",
      " 166500/ 200000: 2.0767\n",
      " 166600/ 200000: 2.0238\n",
      " 166700/ 200000: 1.7373\n",
      " 166800/ 200000: 2.2756\n",
      " 166900/ 200000: 1.8091\n",
      " 167000/ 200000: 2.3445\n",
      " 167100/ 200000: 1.8799\n",
      " 167200/ 200000: 1.9980\n",
      " 167300/ 200000: 2.1554\n",
      " 167400/ 200000: 2.0337\n",
      " 167500/ 200000: 1.9297\n",
      " 167600/ 200000: 2.0262\n",
      " 167700/ 200000: 1.8135\n",
      " 167800/ 200000: 2.3426\n",
      " 167900/ 200000: 2.2126\n",
      " 168000/ 200000: 1.9949\n",
      " 168100/ 200000: 2.3309\n",
      " 168200/ 200000: 1.9100\n",
      " 168300/ 200000: 2.1234\n",
      " 168400/ 200000: 2.2895\n",
      " 168500/ 200000: 2.2188\n",
      " 168600/ 200000: 2.2329\n",
      " 168700/ 200000: 2.2348\n",
      " 168800/ 200000: 2.2092\n",
      " 168900/ 200000: 1.9989\n",
      " 169000/ 200000: 2.3526\n",
      " 169100/ 200000: 2.2480\n",
      " 169200/ 200000: 2.2132\n",
      " 169300/ 200000: 1.8447\n",
      " 169400/ 200000: 1.9730\n",
      " 169500/ 200000: 2.0763\n",
      " 169600/ 200000: 2.1643\n",
      " 169700/ 200000: 2.4183\n",
      " 169800/ 200000: 1.9585\n",
      " 169900/ 200000: 1.9152\n",
      " 170000/ 200000: 1.8475\n",
      " 170100/ 200000: 1.9187\n",
      " 170200/ 200000: 1.9535\n",
      " 170300/ 200000: 2.0390\n",
      " 170400/ 200000: 2.1216\n",
      " 170500/ 200000: 1.9721\n",
      " 170600/ 200000: 2.0120\n",
      " 170700/ 200000: 1.7946\n",
      " 170800/ 200000: 1.8922\n",
      " 170900/ 200000: 2.1633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 171000/ 200000: 2.2050\n",
      " 171100/ 200000: 2.0940\n",
      " 171200/ 200000: 2.0161\n",
      " 171300/ 200000: 2.1374\n",
      " 171400/ 200000: 2.2145\n",
      " 171500/ 200000: 2.1726\n",
      " 171600/ 200000: 2.0249\n",
      " 171700/ 200000: 1.9889\n",
      " 171800/ 200000: 2.0374\n",
      " 171900/ 200000: 2.0377\n",
      " 172000/ 200000: 2.0357\n",
      " 172100/ 200000: 1.9167\n",
      " 172200/ 200000: 1.9108\n",
      " 172300/ 200000: 2.0931\n",
      " 172400/ 200000: 2.4038\n",
      " 172500/ 200000: 2.2631\n",
      " 172600/ 200000: 2.2215\n",
      " 172700/ 200000: 1.9857\n",
      " 172800/ 200000: 1.9047\n",
      " 172900/ 200000: 2.0598\n",
      " 173000/ 200000: 2.0732\n",
      " 173100/ 200000: 2.1613\n",
      " 173200/ 200000: 2.2074\n",
      " 173300/ 200000: 1.9556\n",
      " 173400/ 200000: 1.9040\n",
      " 173500/ 200000: 2.2649\n",
      " 173600/ 200000: 2.0394\n",
      " 173700/ 200000: 2.1798\n",
      " 173800/ 200000: 2.0458\n",
      " 173900/ 200000: 1.8743\n",
      " 174000/ 200000: 2.4218\n",
      " 174100/ 200000: 2.0606\n",
      " 174200/ 200000: 2.2320\n",
      " 174300/ 200000: 2.3616\n",
      " 174400/ 200000: 2.1734\n",
      " 174500/ 200000: 2.3254\n",
      " 174600/ 200000: 2.1821\n",
      " 174700/ 200000: 1.9008\n",
      " 174800/ 200000: 2.3697\n",
      " 174900/ 200000: 2.2621\n",
      " 175000/ 200000: 2.0366\n",
      " 175100/ 200000: 2.2552\n",
      " 175200/ 200000: 2.1139\n",
      " 175300/ 200000: 2.1732\n",
      " 175400/ 200000: 2.2074\n",
      " 175500/ 200000: 2.2257\n",
      " 175600/ 200000: 2.0141\n",
      " 175700/ 200000: 1.9897\n",
      " 175800/ 200000: 2.1341\n",
      " 175900/ 200000: 2.1323\n",
      " 176000/ 200000: 1.8812\n",
      " 176100/ 200000: 2.3132\n",
      " 176200/ 200000: 2.0333\n",
      " 176300/ 200000: 2.3058\n",
      " 176400/ 200000: 2.1916\n",
      " 176500/ 200000: 2.0644\n",
      " 176600/ 200000: 2.1592\n",
      " 176700/ 200000: 2.1211\n",
      " 176800/ 200000: 2.3282\n",
      " 176900/ 200000: 2.3101\n",
      " 177000/ 200000: 2.0223\n",
      " 177100/ 200000: 1.7588\n",
      " 177200/ 200000: 1.8630\n",
      " 177300/ 200000: 1.9975\n",
      " 177400/ 200000: 1.8176\n",
      " 177500/ 200000: 2.0003\n",
      " 177600/ 200000: 2.2335\n",
      " 177700/ 200000: 2.5226\n",
      " 177800/ 200000: 2.1820\n",
      " 177900/ 200000: 2.1159\n",
      " 178000/ 200000: 1.8477\n",
      " 178100/ 200000: 1.9830\n",
      " 178200/ 200000: 2.4935\n",
      " 178300/ 200000: 2.3514\n",
      " 178400/ 200000: 1.7395\n",
      " 178500/ 200000: 1.9262\n",
      " 178600/ 200000: 2.3993\n",
      " 178700/ 200000: 2.1513\n",
      " 178800/ 200000: 1.6407\n",
      " 178900/ 200000: 1.8329\n",
      " 179000/ 200000: 2.0940\n",
      " 179100/ 200000: 2.5421\n",
      " 179200/ 200000: 2.1999\n",
      " 179300/ 200000: 2.2377\n",
      " 179400/ 200000: 1.9825\n",
      " 179500/ 200000: 1.8636\n",
      " 179600/ 200000: 2.0380\n",
      " 179700/ 200000: 1.9428\n",
      " 179800/ 200000: 1.9601\n",
      " 179900/ 200000: 2.2367\n",
      " 180000/ 200000: 1.9902\n",
      " 180100/ 200000: 1.9164\n",
      " 180200/ 200000: 2.2420\n",
      " 180300/ 200000: 2.0479\n",
      " 180400/ 200000: 2.0403\n",
      " 180500/ 200000: 2.0409\n",
      " 180600/ 200000: 1.9983\n",
      " 180700/ 200000: 1.7779\n",
      " 180800/ 200000: 2.0684\n",
      " 180900/ 200000: 2.3243\n",
      " 181000/ 200000: 2.1960\n",
      " 181100/ 200000: 1.9692\n",
      " 181200/ 200000: 1.8344\n",
      " 181300/ 200000: 2.2448\n",
      " 181400/ 200000: 2.4318\n",
      " 181500/ 200000: 2.0340\n",
      " 181600/ 200000: 2.1421\n",
      " 181700/ 200000: 1.9354\n",
      " 181800/ 200000: 1.8971\n",
      " 181900/ 200000: 2.0328\n",
      " 182000/ 200000: 2.1897\n",
      " 182100/ 200000: 2.0403\n",
      " 182200/ 200000: 2.2977\n",
      " 182300/ 200000: 2.3614\n",
      " 182400/ 200000: 1.9333\n",
      " 182500/ 200000: 1.7613\n",
      " 182600/ 200000: 1.8353\n",
      " 182700/ 200000: 2.1449\n",
      " 182800/ 200000: 2.2362\n",
      " 182900/ 200000: 2.1322\n",
      " 183000/ 200000: 2.2696\n",
      " 183100/ 200000: 1.9700\n",
      " 183200/ 200000: 2.0121\n",
      " 183300/ 200000: 2.0619\n",
      " 183400/ 200000: 2.4212\n",
      " 183500/ 200000: 2.4998\n",
      " 183600/ 200000: 2.1134\n",
      " 183700/ 200000: 2.2822\n",
      " 183800/ 200000: 1.9722\n",
      " 183900/ 200000: 2.1920\n",
      " 184000/ 200000: 2.4759\n",
      " 184100/ 200000: 2.0102\n",
      " 184200/ 200000: 2.2258\n",
      " 184300/ 200000: 2.5535\n",
      " 184400/ 200000: 2.0020\n",
      " 184500/ 200000: 1.8305\n",
      " 184600/ 200000: 2.0613\n",
      " 184700/ 200000: 2.2310\n",
      " 184800/ 200000: 1.9934\n",
      " 184900/ 200000: 2.0889\n",
      " 185000/ 200000: 2.3025\n",
      " 185100/ 200000: 1.8612\n",
      " 185200/ 200000: 1.8512\n",
      " 185300/ 200000: 2.0755\n",
      " 185400/ 200000: 2.0394\n",
      " 185500/ 200000: 1.9122\n",
      " 185600/ 200000: 2.3367\n",
      " 185700/ 200000: 1.5660\n",
      " 185800/ 200000: 1.7304\n",
      " 185900/ 200000: 2.5032\n",
      " 186000/ 200000: 1.8723\n",
      " 186100/ 200000: 2.1210\n",
      " 186200/ 200000: 2.0289\n",
      " 186300/ 200000: 1.7458\n",
      " 186400/ 200000: 1.8468\n",
      " 186500/ 200000: 1.9703\n",
      " 186600/ 200000: 2.1570\n",
      " 186700/ 200000: 2.3420\n",
      " 186800/ 200000: 2.1333\n",
      " 186900/ 200000: 2.2480\n",
      " 187000/ 200000: 1.7097\n",
      " 187100/ 200000: 2.1755\n",
      " 187200/ 200000: 1.7895\n",
      " 187300/ 200000: 2.1877\n",
      " 187400/ 200000: 2.0009\n",
      " 187500/ 200000: 1.8258\n",
      " 187600/ 200000: 2.1700\n",
      " 187700/ 200000: 2.0420\n",
      " 187800/ 200000: 1.7923\n",
      " 187900/ 200000: 2.6341\n",
      " 188000/ 200000: 2.2362\n",
      " 188100/ 200000: 1.9130\n",
      " 188200/ 200000: 2.1580\n",
      " 188300/ 200000: 2.4077\n",
      " 188400/ 200000: 1.7924\n",
      " 188500/ 200000: 2.0154\n",
      " 188600/ 200000: 2.1001\n",
      " 188700/ 200000: 1.9602\n",
      " 188800/ 200000: 2.3350\n",
      " 188900/ 200000: 1.9873\n",
      " 189000/ 200000: 2.3548\n",
      " 189100/ 200000: 2.1907\n",
      " 189200/ 200000: 2.0770\n",
      " 189300/ 200000: 2.1699\n",
      " 189400/ 200000: 1.7323\n",
      " 189500/ 200000: 1.8754\n",
      " 189600/ 200000: 2.2442\n",
      " 189700/ 200000: 2.2809\n",
      " 189800/ 200000: 2.5318\n",
      " 189900/ 200000: 2.3659\n",
      " 190000/ 200000: 1.9732\n",
      " 190100/ 200000: 2.2293\n",
      " 190200/ 200000: 1.5491\n",
      " 190300/ 200000: 2.3313\n",
      " 190400/ 200000: 1.8768\n",
      " 190500/ 200000: 1.9848\n",
      " 190600/ 200000: 1.6998\n",
      " 190700/ 200000: 2.0288\n",
      " 190800/ 200000: 1.7465\n",
      " 190900/ 200000: 1.9674\n",
      " 191000/ 200000: 2.1123\n",
      " 191100/ 200000: 1.8161\n",
      " 191200/ 200000: 2.0908\n",
      " 191300/ 200000: 1.8171\n",
      " 191400/ 200000: 2.5761\n",
      " 191500/ 200000: 2.3291\n",
      " 191600/ 200000: 2.3091\n",
      " 191700/ 200000: 2.6047\n",
      " 191800/ 200000: 2.1505\n",
      " 191900/ 200000: 2.3823\n",
      " 192000/ 200000: 2.2253\n",
      " 192100/ 200000: 2.2537\n",
      " 192200/ 200000: 2.1608\n",
      " 192300/ 200000: 2.2701\n",
      " 192400/ 200000: 1.7568\n",
      " 192500/ 200000: 1.8741\n",
      " 192600/ 200000: 2.1766\n",
      " 192700/ 200000: 1.8519\n",
      " 192800/ 200000: 2.0185\n",
      " 192900/ 200000: 1.8424\n",
      " 193000/ 200000: 1.9590\n",
      " 193100/ 200000: 2.0042\n",
      " 193200/ 200000: 2.0320\n",
      " 193300/ 200000: 2.1989\n",
      " 193400/ 200000: 2.1274\n",
      " 193500/ 200000: 1.9500\n",
      " 193600/ 200000: 2.0181\n",
      " 193700/ 200000: 2.0598\n",
      " 193800/ 200000: 1.6441\n",
      " 193900/ 200000: 2.2899\n",
      " 194000/ 200000: 2.0044\n",
      " 194100/ 200000: 1.9245\n",
      " 194200/ 200000: 2.2246\n",
      " 194300/ 200000: 2.3607\n",
      " 194400/ 200000: 2.3687\n",
      " 194500/ 200000: 2.1179\n",
      " 194600/ 200000: 2.0534\n",
      " 194700/ 200000: 2.4574\n",
      " 194800/ 200000: 1.9858\n",
      " 194900/ 200000: 2.3568\n",
      " 195000/ 200000: 2.2699\n",
      " 195100/ 200000: 2.0270\n",
      " 195200/ 200000: 2.3477\n",
      " 195300/ 200000: 2.1331\n",
      " 195400/ 200000: 2.2584\n",
      " 195500/ 200000: 2.0932\n",
      " 195600/ 200000: 1.8971\n",
      " 195700/ 200000: 1.9928\n",
      " 195800/ 200000: 2.3406\n",
      " 195900/ 200000: 2.1005\n",
      " 196000/ 200000: 2.1228\n",
      " 196100/ 200000: 2.1678\n",
      " 196200/ 200000: 2.1527\n",
      " 196300/ 200000: 1.8995\n",
      " 196400/ 200000: 2.3596\n",
      " 196500/ 200000: 2.3426\n",
      " 196600/ 200000: 1.8707\n",
      " 196700/ 200000: 1.7510\n",
      " 196800/ 200000: 1.9673\n",
      " 196900/ 200000: 1.9658\n",
      " 197000/ 200000: 2.0077\n",
      " 197100/ 200000: 2.0285\n",
      " 197200/ 200000: 2.2028\n",
      " 197300/ 200000: 2.0291\n",
      " 197400/ 200000: 2.4778\n",
      " 197500/ 200000: 2.3016\n",
      " 197600/ 200000: 2.2536\n",
      " 197700/ 200000: 2.0573\n",
      " 197800/ 200000: 2.1424\n",
      " 197900/ 200000: 2.3303\n",
      " 198000/ 200000: 2.0257\n",
      " 198100/ 200000: 2.0390\n",
      " 198200/ 200000: 2.1882\n",
      " 198300/ 200000: 2.2959\n",
      " 198400/ 200000: 1.7489\n",
      " 198500/ 200000: 2.3447\n",
      " 198600/ 200000: 2.0217\n",
      " 198700/ 200000: 2.2981\n",
      " 198800/ 200000: 2.0109\n",
      " 198900/ 200000: 1.9590\n",
      " 199000/ 200000: 1.7210\n",
      " 199100/ 200000: 2.1363\n",
      " 199200/ 200000: 1.8015\n",
      " 199300/ 200000: 2.0549\n",
      " 199400/ 200000: 1.9609\n",
      " 199500/ 200000: 2.1769\n",
      " 199600/ 200000: 2.1307\n",
      " 199700/ 200000: 2.2516\n",
      " 199800/ 200000: 1.8576\n",
      " 199900/ 200000: 2.1750\n"
     ]
    }
   ],
   "source": [
    "# the dimentionality of the character embedding vectors\n",
    "n_embd = 10 \n",
    "# the number of neurons in the hidden layer of the MLP\n",
    "n_hidden = 200 \n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1\n",
    "\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency \n",
    "# when your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch \n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] \n",
    "    embcat = emb.view(emb.shape[0], -1) \n",
    "    \n",
    "    # Linear layer\n",
    "    # hidden layer pre-activation\n",
    "    hprebn = embcat @ W1 + b1 \n",
    "    \n",
    "    # BatchNorm layer\n",
    "    # ---------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    \n",
    "    # ------------------------------\n",
    "    # Non-linearity\n",
    "    \n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "        \n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    \n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    \n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    \n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    \n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    \n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    \n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "        for j in range(Xb.shape[1]):\n",
    "            ix = Xb[k,j]\n",
    "            dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad \n",
    "    # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 100 == 0: # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6a79a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # pass the training set through\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    # measure the mean/std over the entire training set\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08d4427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking your gradients\n",
    "# for p,g in zip(parameters, grads):\n",
    "#     cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37f7390b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.071593999862671\n",
      "val 2.109997510910034\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "    emb = C[x] # (N, block_size, n_embd)\n",
    "    embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "    h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "    logits = h @ W2 + b2 # (N, vocab_size)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "450452a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mona.\n",
      "mayah.\n",
      "seel.\n",
      "ndon.\n",
      "alee.\n",
      "thruthadrie.\n",
      "cailee.\n",
      "melin.\n",
      "shi.\n",
      "jenleigh.\n",
      "sana.\n",
      "arleigh.\n",
      "malaia.\n",
      "noshubergahimie.\n",
      "trick.\n",
      "welle.\n",
      "joseus.\n",
      "kuma.\n",
      "geder.\n",
      "yarul.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "        emb = C[torch.tensor([context])] \n",
    "        # (1,block_size,d)      \n",
    "        embcat = emb.view(emb.shape[0], -1) \n",
    "        # concat into (N, block_size * n_embd)\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "        h = torch.tanh(hpreact) \n",
    "        # (N, n_hidden)\n",
    "        logits = h @ W2 + b2\n",
    "        # (N, vocab_size)\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e078e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
